{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c460451",
   "metadata": {},
   "source": [
    "# è·å–ç»æµå­¦äººæ–‡ç« ä¿¡æ¯\n",
    "\n",
    "è·å¾—ç»æµå­¦äººä¸­æœ‰notesçš„åˆŠå·å’Œæ–‡ç« åç§°ï¼Œç”¨äºè·å–ç›¸å…³éŸ³é¢‘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d238a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "def get_closest_json_by_filename(folder):\n",
    "    today = datetime.today().date()\n",
    "    closest_file = None\n",
    "    min_diff = None\n",
    "\n",
    "    for file in os.listdir(folder):\n",
    "        if file.endswith(\".json\"):\n",
    "            name = os.path.splitext(file)[0]\n",
    "            try:\n",
    "                file_date = datetime.strptime(name, \"%Y-%m-%d\").date()\n",
    "                diff = abs((file_date - today).days)\n",
    "                if min_diff is None or diff < min_diff:\n",
    "                    min_diff = diff\n",
    "                    closest_file = file\n",
    "            except ValueError:\n",
    "                # æ–‡ä»¶åä¸æ˜¯æ—¥æœŸæ ¼å¼ï¼Œè·³è¿‡\n",
    "                continue\n",
    "\n",
    "    if closest_file:\n",
    "        closest_path = os.path.join(folder, closest_file)\n",
    "        print(f\"âœ… æœ€æ¥è¿‘ä»Šå¤©çš„æ–‡ä»¶: {closest_path}\")\n",
    "        with open(closest_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            data = json.load(f)\n",
    "        return data\n",
    "    else:\n",
    "        print(\"âŒ æœªæ‰¾åˆ°æ—¥æœŸæ ¼å¼çš„ json æ–‡ä»¶ã€‚\")\n",
    "        return None\n",
    "\n",
    "\n",
    "folder_path = r\"G:\\Code\\Python\\Project\\Reader\\data\\backup\\notes\"\n",
    "json_data = get_closest_json_by_filename(folder_path)\n",
    "\n",
    "pairs = []\n",
    "seen_articles = set()  # ç”¨ set å»é‡ç« èŠ‚\n",
    "\n",
    "for entry in json_data:\n",
    "    bookName = entry.get(\"bookName\", \"\")\n",
    "    chapter = entry.get(\"chapter\", \"\")\n",
    "    chapterIndex = entry.get(\"chapterIndex\", \"\")\n",
    "    if \"The Economist\" in bookName and chapter not in seen_articles:\n",
    "        seen_articles.add(chapter)\n",
    "        pairs.append((bookName, chapter,chapterIndex))\n",
    "\n",
    "# æŒ‰ bookName æ’åº\n",
    "pairs.sort(key=lambda x: x[0])\n",
    "\n",
    "print(\"\\n\".join(f\"{book} - {chapterIndex} - {chapter}\" for book, chapter, chapterIndex in pairs))\n",
    "\n",
    "# chapterIndex + 6 = real index of audio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54f9316",
   "metadata": {},
   "source": [
    "# å¤åˆ¶éŸ³é¢‘æ–‡ä»¶\n",
    "\n",
    "æ ¹æ®æ–‡ç« ä¿¡æ¯å¤åˆ¶å¯¹åº”çš„éŸ³é¢‘æ–‡ä»¶åˆ°å·²è¯»ç›®å½•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70976ced",
   "metadata": {},
   "source": [
    "# æ›´æ–° Media ç‰Œç»„çš„ Definition å’Œ POS_Definitions\n",
    "\n",
    "æ›´æ–° Media ç‰Œç»„ä¸­çš„ definition å’Œ pos_of_definition\n",
    "- é‡æ–°çˆ¬è™«è·å–æœ€æ–°çš„å•è¯ä¿¡æ¯\n",
    "- æ›´æ–° Definition å’Œ POS_Definitions å­—æ®µ\n",
    "- ä¿ç•™å…¶ä»–å­—æ®µï¼ˆExamples, Blanked_Examples ç­‰ï¼‰å’ŒæŸ¥çœ‹è®°å½•\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5384204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "def extract_index(filename: Path):\n",
    "        match = re.match(r\"(\\d+)\", filename.name)\n",
    "        return int(match.group(1)) if match else 999999\n",
    "\n",
    "audio_base_dir = Path(r\"G:\\Book\\Economist\")\n",
    "readed_dir = audio_base_dir / \"ReadedAudio\"\n",
    "\n",
    "for book, chapter, chapterIndex in pairs:\n",
    "    print(book)\n",
    "    # 1. æå–æ–¹æ‹¬å·ä¸­çš„æ—¥æœŸ\n",
    "    match = re.search(r'\\[(.*?)\\]', book)\n",
    "    date_str = match.group(1)  # 'Sep 13th 2025'\n",
    "\n",
    "    # 2. æ¸…æ´—å¹¶è½¬ä¸ºæ ‡å‡†æ—¥æœŸæ ¼å¼\n",
    "    date_str = re.sub(r'(st|nd|rd|th)', '', date_str)  # å»æ‰thç­‰åç¼€\n",
    "    date_obj = datetime.strptime(date_str, '%b %d %Y')\n",
    "    formatted_date = date_obj.strftime('%Y-%m-%d')\n",
    "\n",
    "    # 3. è½¬æ¢ä¸ºæ–‡ä»¶å¤¹æ ¼å¼\n",
    "    folder_date = date_obj.strftime('%Y%m%d')\n",
    "    folder_name = f\"TEco-{folder_date}éŸ³é¢‘\"\n",
    "    folder_path = audio_base_dir / folder_name\n",
    "\n",
    "    mp3_files = [f for f in folder_path.rglob(\"*.mp3\")]\n",
    "    mp3_files_sorted = sorted(mp3_files, key=extract_index)\n",
    "\n",
    "    for mp3_file in mp3_files_sorted:\n",
    "        if extract_index(mp3_file) == chapterIndex + 6:\n",
    "            dest_file = readed_dir / mp3_file.name\n",
    "            if dest_file.exists():\n",
    "                print(f\"âš ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {dest_file.name}\")\n",
    "            else:\n",
    "                shutil.copy2(mp3_file, dest_file)  # æ‹·è´æ–‡ä»¶ï¼Œä¿ç•™å…ƒæ•°æ®\n",
    "                print(f\"âœ… å·²æ‹·è´: {mp3_file.name} -> {readed_dir}\")\n",
    "            print(chapter)\n",
    "            break\n",
    "    # break  # ç¤ºä¾‹åªå¤„ç†ç¬¬ä¸€ä¸ª\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b473fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ›´æ–° Media ç‰Œç»„ä¸­çš„ definition å’Œ pos_of_definition\n",
    "- é‡æ–°çˆ¬è™«è·å–æœ€æ–°çš„å•è¯ä¿¡æ¯\n",
    "- æ›´æ–° Definition å’Œ POS_Definitions å­—æ®µ\n",
    "- ä¿ç•™å…¶ä»–å­—æ®µï¼ˆExamples, Blanked_Examples ç­‰ï¼‰å’ŒæŸ¥çœ‹è®°å½•\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆcode ç›®å½•ï¼‰\n",
    "# åœ¨ notebook ä¸­ï¼Œå½“å‰ç›®å½•é€šå¸¸æ˜¯ code/utilsï¼Œæ‰€ä»¥éœ€è¦å›åˆ° code ç›®å½•\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke, build_html_from_word_info, ensure_pronunciation_audio\n",
    "from dictionary.dict import get_word_info_by_word\n",
    "import requests\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SLEEP_TIME = 0.5  # çˆ¬è™«é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼ˆç”¨äºä»ä¸Šæ¬¡åœæ­¢çš„åœ°æ–¹ç»§ç»­ï¼‰\n",
    "ANKI_RETRY_TIMES = 3  # Anki è¿æ¥å¤±è´¥æ—¶çš„é‡è¯•æ¬¡æ•°\n",
    "ANKI_RETRY_DELAY = 2  # æ¯æ¬¡é‡è¯•ä¹‹é—´çš„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "\n",
    "def invoke_with_retry(action: str, retry_times: int = ANKI_RETRY_TIMES, retry_delay: float = ANKI_RETRY_DELAY, **params):\n",
    "    \"\"\"\n",
    "    å¸¦é‡è¯•æœºåˆ¶çš„ Anki invoke åŒ…è£…å‡½æ•°\n",
    "    \n",
    "    Args:\n",
    "        action: AnkiConnect action åç§°\n",
    "        retry_times: é‡è¯•æ¬¡æ•°\n",
    "        retry_delay: æ¯æ¬¡é‡è¯•ä¹‹é—´çš„ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰\n",
    "        **params: ä¼ é€’ç»™ invoke çš„å‚æ•°\n",
    "    \n",
    "    Returns:\n",
    "        AnkiConnect çš„å“åº”ç»“æœ\n",
    "    \n",
    "    Raises:\n",
    "        Exception: å¦‚æœæ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼ŒæŠ›å‡ºå¼‚å¸¸å¹¶æš‚åœç­‰å¾…ç”¨æˆ·å¤„ç†\n",
    "    \"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(retry_times):\n",
    "        try:\n",
    "            result = anki_invoke(action, **params)\n",
    "            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯\n",
    "            if result and result.get(\"error\"):\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\")\n",
    "                print(f\"  âš ï¸  Anki è¿”å›é”™è¯¯: {error_msg}\")\n",
    "                if attempt < retry_times - 1:\n",
    "                    print(f\"  ğŸ”„ å°†åœ¨ {retry_delay} ç§’åé‡è¯• ({attempt + 1}/{retry_times})...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    last_error = error_msg\n",
    "            else:\n",
    "                return result\n",
    "        except (requests.RequestException, ConnectionError, TimeoutError) as e:\n",
    "            last_error = str(e)\n",
    "            if attempt < retry_times - 1:\n",
    "                print(f\"  âš ï¸  Anki è¿æ¥å¤±è´¥: {e}\")\n",
    "                print(f\"  ğŸ”„ å°†åœ¨ {retry_delay} ç§’åé‡è¯• ({attempt + 1}/{retry_times})...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                print(f\"  âŒ Anki è¿æ¥å¤±è´¥: {e}\")\n",
    "        except Exception as e:\n",
    "            # å…¶ä»–ç±»å‹çš„é”™è¯¯ï¼Œä¸é‡è¯•\n",
    "            raise e\n",
    "    \n",
    "    # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥äº†ï¼Œæš‚åœç­‰å¾…ç”¨æˆ·å¤„ç†\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"âŒ Anki è¿æ¥å¤±è´¥ï¼Œæ‰€æœ‰é‡è¯•éƒ½å·²ç”¨å°½\")\n",
    "    print(f\"   æ“ä½œ: {action}\")\n",
    "    print(f\"   é”™è¯¯: {last_error}\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"\\nè¯·æ£€æŸ¥ä»¥ä¸‹äº‹é¡¹ï¼š\")\n",
    "    print(\"1. Anki æ˜¯å¦æ­£åœ¨è¿è¡Œï¼Ÿ\")\n",
    "    print(\"2. AnkiConnect æ’ä»¶æ˜¯å¦å·²å®‰è£…å¹¶å¯ç”¨ï¼Ÿ\")\n",
    "    print(\"3. ç½‘ç»œè¿æ¥æ˜¯å¦æ­£å¸¸ï¼Ÿ\")\n",
    "    print(\"\\nå¤„ç†å®Œæˆåï¼Œè¯·æŒ‰ Enter é”®ç»§ç»­...\")\n",
    "    \n",
    "    # ç­‰å¾…ç”¨æˆ·è¾“å…¥\n",
    "    try:\n",
    "        input()  # åœ¨ notebook ä¸­ï¼Œè¿™å¯èƒ½éœ€è¦ç”¨æˆ·æ‰‹åŠ¨ç»§ç»­\n",
    "        print(\"âœ… ç»§ç»­å¤„ç†...\")\n",
    "        # å†è¯•ä¸€æ¬¡\n",
    "        return anki_invoke(action, **params)\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œåœæ­¢å¤„ç†\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ ç»§ç»­å°è¯•ä»ç„¶å¤±è´¥: {e}\")\n",
    "        raise\n",
    "\n",
    "def update_media_deck_definitions(deck_name: str = DECK_NAME, sleep: float = SLEEP_TIME, skip_first_n: int = SKIP_FIRST_N):\n",
    "    \"\"\"\n",
    "    æ›´æ–° Media ç‰Œç»„ä¸­æ‰€æœ‰å¡ç‰‡çš„ Definition å’Œ POS_Definitions å­—æ®µ\n",
    "    \n",
    "    Args:\n",
    "        deck_name: ç‰Œç»„åç§°ï¼Œé»˜è®¤ä¸º \"Media\"\n",
    "        sleep: çˆ¬è™«è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "        skip_first_n: è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼Œé»˜è®¤ä¸º 0ï¼ˆä¸è·³è¿‡ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"å¼€å§‹æ›´æ–°ç‰Œç»„ '{deck_name}' ä¸­çš„ definition å’Œ pos_of_definition...\")\n",
    "    if skip_first_n > 0:\n",
    "        print(f\"âš ï¸  å°†è·³è¿‡å‰ {skip_first_n} ä¸ªç¬”è®°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. è·å–ç‰Œç»„ä¸­æ‰€æœ‰ç¬”è®°\n",
    "    query = f'deck:\"{deck_name}\"'\n",
    "    note_ids = invoke_with_retry(\"findNotes\", query=query).get(\"result\", [])\n",
    "    \n",
    "    if not note_ids:\n",
    "        print(f\"âŒ ç‰Œç»„ '{deck_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬”è®°\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "    if skip_first_n > 0:\n",
    "        remaining = len(note_ids) - skip_first_n\n",
    "        print(f\"ğŸ“Š å°†å¤„ç† {remaining} ä¸ªç¬”è®°ï¼ˆè·³è¿‡å‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 2. è·å–æ‰€æœ‰ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯\n",
    "    notes_info = invoke_with_retry(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skip_count = 0\n",
    "    skipped_by_user = 0\n",
    "    \n",
    "    # 3. éå†æ¯ä¸ªç¬”è®°å¹¶æ›´æ–°\n",
    "    for i, note_info in enumerate(notes_info, 1):\n",
    "        # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        if i <= skip_first_n:\n",
    "            skipped_by_user += 1\n",
    "            continue\n",
    "        note_id = note_info.get(\"noteId\")\n",
    "        fields = note_info.get(\"fields\", {})\n",
    "        word_field = fields.get(\"Word\", {})\n",
    "        word = word_field.get(\"value\", \"\").strip() if word_field else \"\"\n",
    "        \n",
    "        if not word:\n",
    "            print(f\"[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šç¬”è®° ID {note_id} æ²¡æœ‰ Word å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "        \n",
    "        try:\n",
    "            # 4. é‡æ–°çˆ¬è™«è·å–æœ€æ–°çš„å•è¯ä¿¡æ¯\n",
    "            print(f\"  æ­£åœ¨ä» Cambridge Dictionary è·å–ä¿¡æ¯...\")\n",
    "            word_info = get_word_info_by_word(word, sleep=sleep)\n",
    "            \n",
    "            if not word_info or not word_info.get(\"partOfSpeech\"):\n",
    "                print(f\"  âš ï¸  æœªè·å–åˆ°å•è¯ä¿¡æ¯ï¼Œè·³è¿‡\")\n",
    "                fail_count += 1\n",
    "                continue\n",
    "            \n",
    "            # 5. æ„å»ºæ–°çš„ Definition å’Œ POS_Definitions HTML\n",
    "            generated_fields = build_html_from_word_info(word_info)\n",
    "            \n",
    "            # 6. è·å–å¹¶ä¿ç•™å‘éŸ³éŸ³é¢‘ï¼ˆå¦‚æœåŸç¬”è®°æœ‰éŸ³é¢‘ï¼Œä¿ç•™ï¼›å¦‚æœæ²¡æœ‰ï¼Œå°è¯•æ·»åŠ ï¼‰\n",
    "            audio_markup = ensure_pronunciation_audio(word_info)\n",
    "            \n",
    "            # æ„å»ºæ›´æ–°å­—æ®µ\n",
    "            update_fields = {}\n",
    "            \n",
    "            # æ›´æ–° Definition å­—æ®µ\n",
    "            new_definition = generated_fields.get(\"Definition\", \"\")\n",
    "            if new_definition:\n",
    "                update_fields[\"Definition\"] = new_definition\n",
    "                print(f\"  âœ… Definition å·²æ›´æ–°\")\n",
    "            \n",
    "            # æ›´æ–° POS_Definitions å­—æ®µ\n",
    "            new_pos_definitions = generated_fields.get(\"POS_Definitions\", \"\")\n",
    "            if new_pos_definitions:\n",
    "                # å¦‚æœæœ‰æ–°çš„éŸ³é¢‘ï¼Œæ·»åŠ åˆ° POS_Definitions å¼€å¤´\n",
    "                if audio_markup:\n",
    "                    existing_pos = note_info.get(\"fields\", {}).get(\"POS_Definitions\", {}).get(\"value\", \"\")\n",
    "                    # å¦‚æœåŸç¬”è®°æ²¡æœ‰éŸ³é¢‘æ ‡è®°ï¼Œæ·»åŠ æ–°çš„éŸ³é¢‘\n",
    "                    if \"[sound:\" not in existing_pos:\n",
    "                        new_pos_definitions = f\"{audio_markup}\\n{new_pos_definitions}\"\n",
    "                update_fields[\"POS_Definitions\"] = new_pos_definitions\n",
    "                print(f\"  âœ… POS_Definitions å·²æ›´æ–°\")\n",
    "            \n",
    "            # 7. æ›´æ–°ç¬”è®°ï¼ˆåªæ›´æ–° Definition å’Œ POS_Definitionsï¼Œä¿ç•™å…¶ä»–å­—æ®µï¼‰\n",
    "            if update_fields:\n",
    "                try:\n",
    "                    result = invoke_with_retry(\"updateNoteFields\", note={\"id\": note_id, \"fields\": update_fields})\n",
    "                    \n",
    "                    if result and not result.get(\"error\"):\n",
    "                        print(f\"  âœ… ç¬”è®°æ›´æ–°æˆåŠŸ\")\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\") if result else \"æ— å“åº”\"\n",
    "                        print(f\"  âŒ æ›´æ–°å¤±è´¥: {error_msg}\")\n",
    "                        fail_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ æ›´æ–°å¤±è´¥ï¼ˆè¿æ¥é—®é¢˜ï¼‰: {e}\")\n",
    "                    fail_count += 1\n",
    "            else:\n",
    "                print(f\"  âš ï¸  æ²¡æœ‰å¯æ›´æ–°çš„å­—æ®µ\")\n",
    "                skip_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            fail_count += 1\n",
    "    \n",
    "    # 8. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ›´æ–°å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸ: {success_count} ä¸ª\")\n",
    "    print(f\"å¤±è´¥: {fail_count} ä¸ª\")\n",
    "    print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "    if skipped_by_user > 0:\n",
    "        print(f\"ç”¨æˆ·è·³è¿‡: {skipped_by_user} ä¸ªï¼ˆå‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(f\"æ€»è®¡: {len(notes_info)} ä¸ª\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œæ›´æ–°\n",
    "# ä¿®æ”¹ SKIP_FIRST_N çš„å€¼æ¥è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼ˆä¾‹å¦‚ï¼šSKIP_FIRST_N = 50 è¡¨ç¤ºè·³è¿‡å‰ 50 ä¸ªï¼‰\n",
    "if __name__ == \"__main__\" or True:  # åœ¨ notebook ä¸­æ€»æ˜¯æ‰§è¡Œ\n",
    "    update_media_deck_definitions(deck_name=DECK_NAME, sleep=SLEEP_TIME, skip_first_n=SKIP_FIRST_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a29470",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ£€æŸ¥å¹¶ä¸Šä¼  Media ç‰Œç»„ä¸­ç¼ºå¤±çš„ mp3 æ–‡ä»¶\n",
    "- ä» Examples å­—æ®µä¸­æå– mp3 æ–‡ä»¶å\n",
    "- æ£€æŸ¥è¿™äº›æ–‡ä»¶æ˜¯å¦å­˜åœ¨äº Anki åª’ä½“åº“\n",
    "- å¦‚æœä¸å­˜åœ¨ï¼Œä»åŸå§‹éŸ³é¢‘ç›®å½•ä¸­æ‰¾åˆ°å¯¹åº”çš„ mp3 æ–‡ä»¶å¹¶ä¸Šä¼ \n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import base64\n",
    "import time\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆcode ç›®å½•ï¼‰\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke\n",
    "from movie.import_to_anki import store_media_file, find_media_files\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "# é…ç½®éŸ³é¢‘ç›®å½•ï¼ˆæ ¹æ®å®é™…æƒ…å†µä¿®æ”¹ï¼‰\n",
    "# å¯ä»¥é…ç½®å¤šä¸ªå¯èƒ½çš„éŸ³é¢‘ç›®å½•\n",
    "# åœ¨ notebook ä¸­ï¼Œéœ€è¦æ ¹æ®å®é™…é¡¹ç›®è·¯å¾„è°ƒæ•´\n",
    "base_dir = Path.cwd().parent.parent if Path.cwd().name == 'utils' else Path.cwd().parent.parent\n",
    "AUDIO_DIRS = [\n",
    "    base_dir / 'data' / 'source' / 'Tenet' / 'audio',\n",
    "    base_dir / 'data' / 'source' / 'Interstellar' / 'audio',\n",
    "    base_dir / 'data' / 'source' / 'The Silence of the Lambs' / 'audio',\n",
    "    base_dir / 'data' / 'source' / 'Green Book' / 'audio',\n",
    "]\n",
    "# è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„ç›®å½•\n",
    "AUDIO_DIRS = [d for d in AUDIO_DIRS if d.exists()]\n",
    "\n",
    "def invoke_with_retry(action: str, retry_times: int = 3, retry_delay: float = 2, **params):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„ Anki invoke åŒ…è£…å‡½æ•°\"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(retry_times):\n",
    "        try:\n",
    "            result = anki_invoke(action, **params)\n",
    "            if result and result.get(\"error\"):\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\")\n",
    "                if attempt < retry_times - 1:\n",
    "                    print(f\"  âš ï¸  Anki è¿”å›é”™è¯¯: {error_msg}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    last_error = error_msg\n",
    "            else:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            last_error = str(e)\n",
    "            if attempt < retry_times - 1:\n",
    "                print(f\"  âš ï¸  Anki è¿æ¥å¤±è´¥: {e}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if last_error:\n",
    "        raise Exception(f\"Anki æ“ä½œå¤±è´¥: {last_error}\")\n",
    "    return result\n",
    "\n",
    "def extract_mp3_filenames_from_examples(examples_html: str) -> list:\n",
    "    \"\"\"ä» Examples å­—æ®µçš„ HTML ä¸­æå–æ‰€æœ‰ mp3 æ–‡ä»¶å\"\"\"\n",
    "    mp3_files = []\n",
    "    \n",
    "    # åŒ¹é… audioEl.src = 'filename.mp3' æ ¼å¼\n",
    "    pattern1 = r\"audioEl\\.src\\s*=\\s*['\\\"]([^'\\\"]+\\.mp3)['\\\"]\"\n",
    "    matches1 = re.findall(pattern1, examples_html, re.IGNORECASE)\n",
    "    mp3_files.extend(matches1)\n",
    "    \n",
    "    # åŒ¹é… [sound:filename.mp3] æ ¼å¼\n",
    "    pattern2 = r\"\\[sound:([^\\]]+\\.mp3)\\]\"\n",
    "    matches2 = re.findall(pattern2, examples_html, re.IGNORECASE)\n",
    "    mp3_files.extend(matches2)\n",
    "    \n",
    "    # å»é‡å¹¶è¿”å›\n",
    "    return list(set(mp3_files))\n",
    "\n",
    "def check_media_file_exists(filename: str) -> bool:\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥ Anki åª’ä½“åº“ä¸­æ˜¯å¦å­˜åœ¨æŒ‡å®šæ–‡ä»¶\n",
    "    æ³¨æ„ï¼šAnkiConnect æ²¡æœ‰ç›´æ¥æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨çš„æ–¹æ³•\n",
    "    è¿™é‡Œæˆ‘ä»¬æ€»æ˜¯è¿”å› Falseï¼Œè®©ä¸Šä¼ é€»è¾‘å¤„ç†ï¼ˆå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œä¸Šä¼ ä¼šæˆåŠŸä½†ä¸ä¼šè¦†ç›–ï¼‰\n",
    "    \"\"\"\n",
    "    # AnkiConnect çš„ storeMediaFile å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œä¼šè¿”å›æˆåŠŸä½†ä¸ä¼šè¦†ç›–\n",
    "    # æ‰€ä»¥æˆ‘ä»¬ç›´æ¥è¿”å› Falseï¼Œè®©ä¸Šä¼ é€»è¾‘å¤„ç†\n",
    "    return False\n",
    "\n",
    "def convert_filename_to_new_format(old_filename: str) -> str:\n",
    "    \"\"\"\n",
    "    å°†æ—§æ ¼å¼æ–‡ä»¶åè½¬æ¢ä¸ºæ–°æ ¼å¼\n",
    "    æ—§æ ¼å¼ï¼šå•è¯_åºå·.mp3 (å¦‚ transcend_03.mp3)\n",
    "    æ–°æ ¼å¼ï¼šåºå·_å•è¯.mp3 (å¦‚ 03_transcend.mp3)\n",
    "    \"\"\"\n",
    "    name_without_ext = Path(old_filename).stem\n",
    "    ext = Path(old_filename).suffix\n",
    "    \n",
    "    # å°è¯•åŒ¹é…æ—§æ ¼å¼ï¼šå•è¯_åºå·\n",
    "    match = re.match(r'^(.+?)_(\\d+)$', name_without_ext)\n",
    "    if match:\n",
    "        word = match.group(1)\n",
    "        number = match.group(2)\n",
    "        # è½¬æ¢ä¸ºæ–°æ ¼å¼ï¼šåºå·_å•è¯\n",
    "        new_filename = f\"{number}_{word}{ext}\"\n",
    "        return new_filename\n",
    "    \n",
    "    # å¦‚æœå·²ç»æ˜¯æ–°æ ¼å¼æˆ–æ— æ³•åŒ¹é…ï¼Œè¿”å›åŸæ–‡ä»¶å\n",
    "    return old_filename\n",
    "\n",
    "def find_mp3_file_in_dirs(filename: str, audio_dirs: list) -> tuple:\n",
    "    \"\"\"\n",
    "    åœ¨éŸ³é¢‘ç›®å½•ä¸­æŸ¥æ‰¾å¯¹åº”çš„ mp3 æ–‡ä»¶\n",
    "    è¿”å›: (æ–‡ä»¶è·¯å¾„, æ–°æ ¼å¼æ–‡ä»¶å) æˆ– (None, None)\n",
    "    å¦‚æœæ‰¾åˆ°æ—§æ ¼å¼æ–‡ä»¶ï¼Œä¼šè½¬æ¢ä¸ºæ–°æ ¼å¼æ–‡ä»¶å\n",
    "    \"\"\"\n",
    "    filename_only = Path(filename).name\n",
    "    name_without_ext = Path(filename_only).stem\n",
    "    \n",
    "    # å°è¯•åŒ¹é…æ—§æ ¼å¼ï¼šå•è¯_åºå·\n",
    "    match_old = re.match(r'^(.+?)_(\\d+)$', name_without_ext)\n",
    "    # å°è¯•åŒ¹é…æ–°æ ¼å¼ï¼šåºå·_å•è¯\n",
    "    match_new = re.match(r'^(\\d+)_(.+)$', name_without_ext)\n",
    "    \n",
    "    for audio_dir in audio_dirs:\n",
    "        if not audio_dir or not audio_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # 1. ç›´æ¥æŸ¥æ‰¾æ–‡ä»¶åï¼ˆæ–°æ ¼å¼æˆ–æ—§æ ¼å¼ï¼‰\n",
    "        mp3_file = audio_dir / filename_only\n",
    "        if mp3_file.exists():\n",
    "            # æ£€æŸ¥æ˜¯å¦æ˜¯æ—§æ ¼å¼ï¼Œå¦‚æœæ˜¯åˆ™è½¬æ¢ä¸ºæ–°æ ¼å¼\n",
    "            new_filename = convert_filename_to_new_format(filename_only)\n",
    "            return mp3_file, new_filename\n",
    "        \n",
    "        # 2. å¦‚æœæ–‡ä»¶åæ˜¯æ—§æ ¼å¼ï¼ˆå•è¯_åºå·ï¼‰ï¼Œå°è¯•æŸ¥æ‰¾æ–°æ ¼å¼æ–‡ä»¶\n",
    "        if match_old:\n",
    "            word = match_old.group(1)\n",
    "            number = match_old.group(2)\n",
    "            # æŸ¥æ‰¾æ–°æ ¼å¼ï¼šåºå·_å•è¯.mp3\n",
    "            new_pattern = f\"{number}_{word}.mp3\"\n",
    "            new_file = audio_dir / new_pattern\n",
    "            if new_file.exists():\n",
    "                return new_file, new_pattern\n",
    "        \n",
    "        # 3. å¦‚æœæ–‡ä»¶åæ˜¯æ–°æ ¼å¼ï¼ˆåºå·_å•è¯ï¼‰ï¼Œç›´æ¥æŸ¥æ‰¾\n",
    "        if match_new:\n",
    "            number = match_new.group(1)\n",
    "            word = match_new.group(2)\n",
    "            pattern = f\"{number}_{word}.mp3\"\n",
    "            new_file = audio_dir / pattern\n",
    "            if new_file.exists():\n",
    "                return new_file, pattern\n",
    "        \n",
    "        # 4. å¦‚æœæ–‡ä»¶åæ˜¯æ—§æ ¼å¼ï¼Œå°è¯•é€šè¿‡å•è¯æŸ¥æ‰¾æ—§æ ¼å¼æ–‡ä»¶\n",
    "        if match_old:\n",
    "            word = match_old.group(1)\n",
    "            pattern_old = f\"{word}_*.mp3\"\n",
    "            matches = list(audio_dir.glob(pattern_old))\n",
    "            if matches:\n",
    "                # æ‰¾åˆ°æ—§æ ¼å¼æ–‡ä»¶ï¼Œè½¬æ¢ä¸ºæ–°æ ¼å¼\n",
    "                old_file = matches[0]\n",
    "                new_filename = convert_filename_to_new_format(old_file.name)\n",
    "                return old_file, new_filename\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def check_and_upload_missing_mp3s(deck_name: str = DECK_NAME, skip_first_n: int = SKIP_FIRST_N, audio_dirs: list = None):\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥ Media ç‰Œç»„ä¸­ç¼ºå¤±çš„ mp3 æ–‡ä»¶å¹¶ä¸Šä¼ \n",
    "    \n",
    "    Args:\n",
    "        deck_name: ç‰Œç»„åç§°\n",
    "        skip_first_n: è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        audio_dirs: éŸ³é¢‘ç›®å½•åˆ—è¡¨ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®\n",
    "    \"\"\"\n",
    "    if audio_dirs is None:\n",
    "        audio_dirs = AUDIO_DIRS\n",
    "    \n",
    "    print(f\"å¼€å§‹æ£€æŸ¥ç‰Œç»„ '{deck_name}' ä¸­ç¼ºå¤±çš„ mp3 æ–‡ä»¶...\")\n",
    "    if skip_first_n > 0:\n",
    "        print(f\"âš ï¸  å°†è·³è¿‡å‰ {skip_first_n} ä¸ªç¬”è®°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ˜¾ç¤ºé…ç½®çš„éŸ³é¢‘ç›®å½•\n",
    "    print(\"é…ç½®çš„éŸ³é¢‘ç›®å½•:\")\n",
    "    for i, audio_dir in enumerate(audio_dirs, 1):\n",
    "        exists = \"âœ…\" if audio_dir and audio_dir.exists() else \"âŒ\"\n",
    "        print(f\"  {i}. {exists} {audio_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. è·å–ç‰Œç»„ä¸­æ‰€æœ‰ç¬”è®°\n",
    "    query = f'deck:\"{deck_name}\"'\n",
    "    note_ids = invoke_with_retry(\"findNotes\", query=query).get(\"result\", [])\n",
    "    \n",
    "    if not note_ids:\n",
    "        print(f\"âŒ ç‰Œç»„ '{deck_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬”è®°\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "    if skip_first_n > 0:\n",
    "        remaining = len(note_ids) - skip_first_n\n",
    "        print(f\"ğŸ“Š å°†å¤„ç† {remaining} ä¸ªç¬”è®°ï¼ˆè·³è¿‡å‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 2. è·å–æ‰€æœ‰ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯\n",
    "    notes_info = invoke_with_retry(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skip_count = 0\n",
    "    skipped_by_user = 0\n",
    "    \n",
    "    # 3. éå†æ¯ä¸ªç¬”è®°\n",
    "    for i, note_info in enumerate(notes_info, 1):\n",
    "        # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        if i <= skip_first_n:\n",
    "            skipped_by_user += 1\n",
    "            continue\n",
    "        \n",
    "        note_id = note_info.get(\"noteId\")\n",
    "        fields = note_info.get(\"fields\", {})\n",
    "        word_field = fields.get(\"Word\", {})\n",
    "        word = word_field.get(\"value\", \"\").strip() if word_field else \"\"\n",
    "        examples_field = fields.get(\"Examples\", {})\n",
    "        examples_html = examples_field.get(\"value\", \"\") if examples_field else \"\"\n",
    "        \n",
    "        if not word:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šç¬”è®° ID {note_id} æ²¡æœ‰ Word å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        if not examples_html:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šå•è¯ '{word}' æ²¡æœ‰ Examples å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "        \n",
    "        try:\n",
    "            # 4. ä» Examples å­—æ®µä¸­æå– mp3 æ–‡ä»¶å\n",
    "            mp3_filenames = extract_mp3_filenames_from_examples(examples_html)\n",
    "            \n",
    "            if not mp3_filenames:\n",
    "                print(f\"  âš ï¸  æœªæ‰¾åˆ° mp3 æ–‡ä»¶å¼•ç”¨\")\n",
    "                skip_count += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ğŸ“‹ æ‰¾åˆ° {len(mp3_filenames)} ä¸ª mp3 æ–‡ä»¶å¼•ç”¨: {', '.join(mp3_filenames)}\")\n",
    "            \n",
    "            # 5. å¤„ç†æ¯ä¸ª mp3 æ–‡ä»¶ï¼ˆæ£€æŸ¥å¹¶ä¸Šä¼ ï¼‰\n",
    "            for mp3_filename in mp3_filenames:\n",
    "                # åœ¨éŸ³é¢‘ç›®å½•ä¸­æŸ¥æ‰¾æ–‡ä»¶\n",
    "                mp3_file, new_filename = find_mp3_file_in_dirs(mp3_filename, audio_dirs)\n",
    "                \n",
    "                if not mp3_file:\n",
    "                    print(f\"  âš ï¸  æœªæ‰¾åˆ°æºæ–‡ä»¶: {mp3_filename}\")\n",
    "                    fail_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # å¦‚æœæ–‡ä»¶åéœ€è¦è½¬æ¢ï¼ˆæ—§æ ¼å¼è½¬æ–°æ ¼å¼ï¼‰\n",
    "                if new_filename != mp3_filename:\n",
    "                    print(f\"  ğŸ”„ æ–‡ä»¶åæ ¼å¼è½¬æ¢: {mp3_filename} -> {new_filename}\")\n",
    "                    upload_filename = new_filename\n",
    "                else:\n",
    "                    upload_filename = mp3_filename\n",
    "                \n",
    "                print(f\"  ğŸ“ æ‰¾åˆ°æºæ–‡ä»¶: {mp3_file.name}\")\n",
    "                \n",
    "                # ä¸Šä¼ æ–‡ä»¶ï¼ˆä½¿ç”¨æ–°æ ¼å¼æ–‡ä»¶åï¼‰\n",
    "                try:\n",
    "                    if store_media_file(str(mp3_file), upload_filename):\n",
    "                        print(f\"  âœ… æˆåŠŸä¸Šä¼ : {upload_filename}\")\n",
    "                        success_count += 1\n",
    "                        \n",
    "                        # å¦‚æœæ–‡ä»¶åè¢«è½¬æ¢äº†ï¼Œéœ€è¦æ›´æ–° Examples å­—æ®µä¸­çš„å¼•ç”¨\n",
    "                        if new_filename != mp3_filename:\n",
    "                            print(f\"  ğŸ”„ éœ€è¦æ›´æ–° Examples å­—æ®µä¸­çš„æ–‡ä»¶åå¼•ç”¨\")\n",
    "                            # æ›´æ–° Examples å­—æ®µä¸­çš„æ–‡ä»¶å\n",
    "                            updated_examples = examples_html.replace(mp3_filename, upload_filename)\n",
    "                            if updated_examples != examples_html:\n",
    "                                try:\n",
    "                                    result = invoke_with_retry(\"updateNoteFields\", \n",
    "                                                             note={\"id\": note_id, \n",
    "                                                                   \"fields\": {\"Examples\": updated_examples}})\n",
    "                                    if result and not result.get(\"error\"):\n",
    "                                        print(f\"  âœ… å·²æ›´æ–° Examples å­—æ®µä¸­çš„æ–‡ä»¶åå¼•ç”¨\")\n",
    "                                    else:\n",
    "                                        print(f\"  âš ï¸  æ›´æ–° Examples å­—æ®µå¤±è´¥ï¼Œä½†æ–‡ä»¶å·²ä¸Šä¼ \")\n",
    "                                except Exception as e:\n",
    "                                    print(f\"  âš ï¸  æ›´æ–° Examples å­—æ®µå¼‚å¸¸: {e}\")\n",
    "                    else:\n",
    "                        print(f\"  âŒ ä¸Šä¼ å¤±è´¥: {upload_filename}\")\n",
    "                        fail_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ ä¸Šä¼ å¼‚å¸¸: {upload_filename} - {e}\")\n",
    "                    fail_count += 1\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            fail_count += 1\n",
    "    \n",
    "    # 7. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"æ£€æŸ¥å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸä¸Šä¼ : {success_count} ä¸ª\")\n",
    "    print(f\"å¤±è´¥: {fail_count} ä¸ª\")\n",
    "    print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "    if skipped_by_user > 0:\n",
    "        print(f\"ç”¨æˆ·è·³è¿‡: {skipped_by_user} ä¸ªï¼ˆå‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(f\"æ€»è®¡: {len(notes_info)} ä¸ª\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œæ£€æŸ¥\n",
    "# ä¿®æ”¹ SKIP_FIRST_N çš„å€¼æ¥è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "# ä¿®æ”¹ AUDIO_DIRS æ¥é…ç½®éŸ³é¢‘ç›®å½•\n",
    "if __name__ == \"__main__\" or True:  # åœ¨ notebook ä¸­æ€»æ˜¯æ‰§è¡Œ\n",
    "    check_and_upload_missing_mp3s(deck_name=DECK_NAME, skip_first_n=SKIP_FIRST_N, audio_dirs=AUDIO_DIRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a354f027",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "å¤„ç†æ‰€æœ‰ tag ä¸º \"tenet\" çš„å¡ç‰Œï¼Œå°† mp3 æ–‡ä»¶ä¸ reference.mp3 ä¸€è‡´åé‡æ–°ä¸Šä¼ \n",
    "- æŸ¥æ‰¾æ‰€æœ‰ tag ä¸º \"tenet\" çš„ç¬”è®°\n",
    "- ä» Examples å­—æ®µä¸­æå– mp3 æ–‡ä»¶å\n",
    "- æ‰¾åˆ°å¯¹åº”çš„æºæ–‡ä»¶\n",
    "- ä½¿ç”¨ reference.mp3 çš„ LUFS å€¼æ ‡å‡†åŒ–éŸ³é¢‘éŸ³é‡\n",
    "- é‡æ–°ä¸Šä¼ å¤„ç†åçš„æ–‡ä»¶\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "import tempfile\n",
    "import os\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆcode ç›®å½•ï¼‰\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke\n",
    "from movie.import_to_anki import store_media_file\n",
    "from movie.extract_audio import get_audio_lufs, normalize_audio_volume\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "TAG_NAME = \"tenet\"\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "\n",
    "# é…ç½®è·¯å¾„\n",
    "base_dir = Path.cwd().parent.parent if Path.cwd().name == 'utils' else Path.cwd().parent.parent\n",
    "REFERENCE_AUDIO = base_dir / 'data' / 'source' / 'reference.mp3'\n",
    "AUDIO_DIRS = [\n",
    "    base_dir / 'data' / 'source' / 'Tenet' / 'audio',\n",
    "    base_dir / 'data' / 'source' / 'Interstellar' / 'audio',\n",
    "]\n",
    "# è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„ç›®å½•\n",
    "AUDIO_DIRS = [d for d in AUDIO_DIRS if d.exists()]\n",
    "\n",
    "def invoke_with_retry(action: str, retry_times: int = 3, retry_delay: float = 2, **params):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„ Anki invoke åŒ…è£…å‡½æ•°\"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(retry_times):\n",
    "        try:\n",
    "            result = anki_invoke(action, **params)\n",
    "            if result and result.get(\"error\"):\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\")\n",
    "                if attempt < retry_times - 1:\n",
    "                    print(f\"  âš ï¸  Anki è¿”å›é”™è¯¯: {error_msg}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    last_error = error_msg\n",
    "            else:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            last_error = str(e)\n",
    "            if attempt < retry_times - 1:\n",
    "                print(f\"  âš ï¸  Anki è¿æ¥å¤±è´¥: {e}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if last_error:\n",
    "        raise Exception(f\"Anki æ“ä½œå¤±è´¥: {last_error}\")\n",
    "    return result\n",
    "\n",
    "def extract_mp3_filenames_from_examples(examples_html: str) -> list:\n",
    "    \"\"\"ä» Examples å­—æ®µçš„ HTML ä¸­æå–æ‰€æœ‰ mp3 æ–‡ä»¶å\"\"\"\n",
    "    mp3_files = []\n",
    "    \n",
    "    # åŒ¹é… audioEl.src = 'filename.mp3' æ ¼å¼\n",
    "    pattern1 = r\"audioEl\\.src\\s*=\\s*['\\\"]([^'\\\"]+\\.mp3)['\\\"]\"\n",
    "    matches1 = re.findall(pattern1, examples_html, re.IGNORECASE)\n",
    "    mp3_files.extend(matches1)\n",
    "    \n",
    "    # åŒ¹é… [sound:filename.mp3] æ ¼å¼\n",
    "    pattern2 = r\"\\[sound:([^\\]]+\\.mp3)\\]\"\n",
    "    matches2 = re.findall(pattern2, examples_html, re.IGNORECASE)\n",
    "    mp3_files.extend(matches2)\n",
    "    \n",
    "    # å»é‡å¹¶è¿”å›\n",
    "    return list(set(mp3_files))\n",
    "\n",
    "def find_mp3_file_in_dirs(filename: str, audio_dirs: list) -> Path:\n",
    "    \"\"\"åœ¨éŸ³é¢‘ç›®å½•ä¸­æŸ¥æ‰¾å¯¹åº”çš„ mp3 æ–‡ä»¶\"\"\"\n",
    "    filename_only = Path(filename).name\n",
    "    \n",
    "    for audio_dir in audio_dirs:\n",
    "        if not audio_dir or not audio_dir.exists():\n",
    "            continue\n",
    "        \n",
    "        # ç›´æ¥æŸ¥æ‰¾æ–‡ä»¶å\n",
    "        mp3_file = audio_dir / filename_only\n",
    "        if mp3_file.exists():\n",
    "            return mp3_file\n",
    "        \n",
    "        # å°è¯•åŒ¹é…æ•°å­—_å•è¯æ ¼å¼ï¼ˆæ–°æ ¼å¼ï¼‰\n",
    "        name_without_ext = Path(filename_only).stem\n",
    "        match_new = re.match(r'^(\\d+)_(.+)$', name_without_ext)\n",
    "        if match_new:\n",
    "            number = match_new.group(1)\n",
    "            word = match_new.group(2)\n",
    "            pattern = f\"{number}_{word}.mp3\"\n",
    "            new_file = audio_dir / pattern\n",
    "            if new_file.exists():\n",
    "                return new_file\n",
    "        \n",
    "        # å°è¯•åŒ¹é…å•è¯_æ•°å­—æ ¼å¼ï¼ˆæ—§æ ¼å¼ï¼‰\n",
    "        match_old = re.match(r'^(.+?)_(\\d+)$', name_without_ext)\n",
    "        if match_old:\n",
    "            word = match_old.group(1)\n",
    "            number = match_old.group(2)\n",
    "            # æŸ¥æ‰¾æ–°æ ¼å¼\n",
    "            new_pattern = f\"{number}_{word}.mp3\"\n",
    "            new_file = audio_dir / new_pattern\n",
    "            if new_file.exists():\n",
    "                return new_file\n",
    "            # æŸ¥æ‰¾æ—§æ ¼å¼\n",
    "            old_pattern = f\"{word}_{number}.mp3\"\n",
    "            old_file = audio_dir / old_pattern\n",
    "            if old_file.exists():\n",
    "                return old_file\n",
    "    \n",
    "    return None\n",
    "\n",
    "def normalize_and_upload_tenet_mp3s(deck_name: str = DECK_NAME, tag_name: str = TAG_NAME, \n",
    "                                    skip_first_n: int = SKIP_FIRST_N, \n",
    "                                    reference_audio: Path = REFERENCE_AUDIO,\n",
    "                                    audio_dirs: list = None):\n",
    "    \"\"\"\n",
    "    å¤„ç†æ‰€æœ‰ tag ä¸ºæŒ‡å®šæ ‡ç­¾çš„å¡ç‰Œï¼Œå°† mp3 æ–‡ä»¶ä¸ reference.mp3 ä¸€è‡´åé‡æ–°ä¸Šä¼ \n",
    "    \n",
    "    Args:\n",
    "        deck_name: ç‰Œç»„åç§°\n",
    "        tag_name: æ ‡ç­¾åç§°\n",
    "        skip_first_n: è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        reference_audio: å‚è€ƒéŸ³é¢‘æ–‡ä»¶è·¯å¾„\n",
    "        audio_dirs: éŸ³é¢‘ç›®å½•åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    if audio_dirs is None:\n",
    "        audio_dirs = AUDIO_DIRS\n",
    "    \n",
    "    print(f\"å¼€å§‹å¤„ç†ç‰Œç»„ '{deck_name}' ä¸­ tag ä¸º '{tag_name}' çš„å¡ç‰Œ...\")\n",
    "    if skip_first_n > 0:\n",
    "        print(f\"âš ï¸  å°†è·³è¿‡å‰ {skip_first_n} ä¸ªç¬”è®°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ£€æŸ¥å‚è€ƒéŸ³é¢‘æ–‡ä»¶\n",
    "    if not reference_audio.exists():\n",
    "        print(f\"âŒ å‚è€ƒéŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {reference_audio}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"ğŸ“ å‚è€ƒéŸ³é¢‘: {reference_audio}\")\n",
    "    \n",
    "    # è·å–å‚è€ƒéŸ³é¢‘çš„ LUFS å€¼\n",
    "    print(\"æ­£åœ¨åˆ†æå‚è€ƒéŸ³é¢‘çš„ LUFS å€¼...\")\n",
    "    target_lufs = get_audio_lufs(str(reference_audio))\n",
    "    if target_lufs is None:\n",
    "        print(\"âš ï¸  æ— æ³•è·å–å‚è€ƒéŸ³é¢‘ LUFS å€¼ï¼Œä½¿ç”¨é»˜è®¤å€¼ -23.0\")\n",
    "        target_lufs = -23.0\n",
    "    else:\n",
    "        print(f\"âœ… å‚è€ƒéŸ³é¢‘ LUFS å€¼: {target_lufs:.2f}\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # æ˜¾ç¤ºé…ç½®çš„éŸ³é¢‘ç›®å½•\n",
    "    print(\"é…ç½®çš„éŸ³é¢‘ç›®å½•:\")\n",
    "    for i, audio_dir in enumerate(audio_dirs, 1):\n",
    "        exists = \"âœ…\" if audio_dir and audio_dir.exists() else \"âŒ\"\n",
    "        print(f\"  {i}. {exists} {audio_dir}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. æŸ¥æ‰¾æ‰€æœ‰ tag ä¸ºæŒ‡å®šæ ‡ç­¾çš„ç¬”è®°\n",
    "    query = f'deck:\"{deck_name}\" tag:{tag_name}'\n",
    "    note_ids = invoke_with_retry(\"findNotes\", query=query).get(\"result\", [])\n",
    "    \n",
    "    if not note_ids:\n",
    "        print(f\"âŒ ç‰Œç»„ '{deck_name}' ä¸­æ²¡æœ‰æ‰¾åˆ° tag ä¸º '{tag_name}' çš„ç¬”è®°\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°ï¼ˆtag: {tag_name}ï¼‰\")\n",
    "    if skip_first_n > 0:\n",
    "        remaining = len(note_ids) - skip_first_n\n",
    "        print(f\"ğŸ“Š å°†å¤„ç† {remaining} ä¸ªç¬”è®°ï¼ˆè·³è¿‡å‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 2. è·å–æ‰€æœ‰ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯\n",
    "    notes_info = invoke_with_retry(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skip_count = 0\n",
    "    skipped_by_user = 0\n",
    "    \n",
    "    # 3. éå†æ¯ä¸ªç¬”è®°\n",
    "    for i, note_info in enumerate(notes_info, 1):\n",
    "        # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        if i <= skip_first_n:\n",
    "            skipped_by_user += 1\n",
    "            continue\n",
    "        \n",
    "        note_id = note_info.get(\"noteId\")\n",
    "        fields = note_info.get(\"fields\", {})\n",
    "        word_field = fields.get(\"Word\", {})\n",
    "        word = word_field.get(\"value\", \"\").strip() if word_field else \"\"\n",
    "        examples_field = fields.get(\"Examples\", {})\n",
    "        examples_html = examples_field.get(\"value\", \"\") if examples_field else \"\"\n",
    "        \n",
    "        if not word:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šç¬”è®° ID {note_id} æ²¡æœ‰ Word å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        if not examples_html:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šå•è¯ '{word}' æ²¡æœ‰ Examples å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "        \n",
    "        try:\n",
    "            # 4. ä» Examples å­—æ®µä¸­æå– mp3 æ–‡ä»¶å\n",
    "            mp3_filenames = extract_mp3_filenames_from_examples(examples_html)\n",
    "            \n",
    "            if not mp3_filenames:\n",
    "                print(f\"  âš ï¸  æœªæ‰¾åˆ° mp3 æ–‡ä»¶å¼•ç”¨\")\n",
    "                skip_count += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ğŸ“‹ æ‰¾åˆ° {len(mp3_filenames)} ä¸ª mp3 æ–‡ä»¶å¼•ç”¨: {', '.join(mp3_filenames)}\")\n",
    "            \n",
    "            # 5. å¤„ç†æ¯ä¸ª mp3 æ–‡ä»¶\n",
    "            for mp3_filename in mp3_filenames:\n",
    "                # åœ¨éŸ³é¢‘ç›®å½•ä¸­æŸ¥æ‰¾æºæ–‡ä»¶\n",
    "                source_file = find_mp3_file_in_dirs(mp3_filename, audio_dirs)\n",
    "                \n",
    "                if not source_file:\n",
    "                    print(f\"  âš ï¸  æœªæ‰¾åˆ°æºæ–‡ä»¶: {mp3_filename}\")\n",
    "                    fail_count += 1\n",
    "                    continue\n",
    "                \n",
    "                print(f\"  ğŸ“ æ‰¾åˆ°æºæ–‡ä»¶: {source_file.name}\")\n",
    "                \n",
    "                # 6. æ ‡å‡†åŒ–éŸ³é¢‘éŸ³é‡\n",
    "                print(f\"  ğŸ”„ æ­£åœ¨æ ‡å‡†åŒ–éŸ³é¢‘éŸ³é‡ï¼ˆç›®æ ‡ LUFS: {target_lufs:.2f}ï¼‰...\")\n",
    "                \n",
    "                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶\n",
    "                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp_file:\n",
    "                    temp_output = tmp_file.name\n",
    "                \n",
    "                try:\n",
    "                    # æ ‡å‡†åŒ–éŸ³é‡\n",
    "                    if normalize_audio_volume(str(source_file), temp_output, target_lufs):\n",
    "                        print(f\"  âœ… éŸ³é¢‘æ ‡å‡†åŒ–æˆåŠŸ\")\n",
    "                        \n",
    "                        # 7. ä¸Šä¼ å¤„ç†åçš„æ–‡ä»¶\n",
    "                        if store_media_file(temp_output, mp3_filename):\n",
    "                            print(f\"  âœ… æˆåŠŸä¸Šä¼ : {mp3_filename}\")\n",
    "                            success_count += 1\n",
    "                        else:\n",
    "                            print(f\"  âŒ ä¸Šä¼ å¤±è´¥: {mp3_filename}\")\n",
    "                            fail_count += 1\n",
    "                    else:\n",
    "                        print(f\"  âŒ éŸ³é¢‘æ ‡å‡†åŒ–å¤±è´¥: {mp3_filename}\")\n",
    "                        fail_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ å¤„ç†å¼‚å¸¸: {mp3_filename} - {e}\")\n",
    "                    fail_count += 1\n",
    "                finally:\n",
    "                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶\n",
    "                    try:\n",
    "                        if os.path.exists(temp_output):\n",
    "                            os.remove(temp_output)\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            fail_count += 1\n",
    "    \n",
    "    # 8. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸå¤„ç†å¹¶ä¸Šä¼ : {success_count} ä¸ª\")\n",
    "    print(f\"å¤±è´¥: {fail_count} ä¸ª\")\n",
    "    print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "    if skipped_by_user > 0:\n",
    "        print(f\"ç”¨æˆ·è·³è¿‡: {skipped_by_user} ä¸ªï¼ˆå‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(f\"æ€»è®¡: {len(notes_info)} ä¸ª\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œå¤„ç†\n",
    "# ä¿®æ”¹ SKIP_FIRST_N çš„å€¼æ¥è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "# ä¿®æ”¹ TAG_NAME æ¥æŒ‡å®šä¸åŒçš„æ ‡ç­¾\n",
    "if __name__ == \"__main__\" or True:  # åœ¨ notebook ä¸­æ€»æ˜¯æ‰§è¡Œ\n",
    "    normalize_and_upload_tenet_mp3s(deck_name=DECK_NAME, tag_name=TAG_NAME, \n",
    "                                    skip_first_n=SKIP_FIRST_N, \n",
    "                                    reference_audio=REFERENCE_AUDIO,\n",
    "                                    audio_dirs=AUDIO_DIRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70c88c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ä¸º Media ç‰Œç»„ä¸­ç¼ºå°‘è¯»éŸ³çš„å¡ç‰‡é‡æ–°çˆ¬è™«å¹¶ä¸Šä¼  mp3 å‘éŸ³\n",
    "- æŸ¥æ‰¾æ‰€æœ‰ Media ç‰Œç»„ä¸­çš„ç¬”è®°\n",
    "- æ£€æŸ¥ Pronunciation å’Œ POS_Definitions å­—æ®µæ˜¯å¦åŒ…å« [sound:...] æ ‡è®°\n",
    "- å¦‚æœæ²¡æœ‰ï¼Œé‡æ–°ä» Cambridge Dictionary çˆ¬è™«è·å–å•è¯ä¿¡æ¯\n",
    "- ä¸‹è½½å‘éŸ³éŸ³é¢‘å¹¶ä¸Šä¼ åˆ° Anki\n",
    "- æ›´æ–° Pronunciation å’Œ POS_Definitions å­—æ®µ\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆcode ç›®å½•ï¼‰\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke, ensure_pronunciation_audio\n",
    "from dictionary.dict import get_word_info_by_word\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SLEEP_TIME = 0.5  # çˆ¬è™«é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "\n",
    "def invoke_with_retry(action: str, retry_times: int = 3, retry_delay: float = 2, **params):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„ Anki invoke åŒ…è£…å‡½æ•°\"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(retry_times):\n",
    "        try:\n",
    "            result = anki_invoke(action, **params)\n",
    "            if result and result.get(\"error\"):\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\")\n",
    "                if attempt < retry_times - 1:\n",
    "                    print(f\"  âš ï¸  Anki è¿”å›é”™è¯¯: {error_msg}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    last_error = error_msg\n",
    "            else:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            last_error = str(e)\n",
    "            if attempt < retry_times - 1:\n",
    "                print(f\"  âš ï¸  Anki è¿æ¥å¤±è´¥: {e}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if last_error:\n",
    "        raise Exception(f\"Anki æ“ä½œå¤±è´¥: {last_error}\")\n",
    "    return result\n",
    "\n",
    "def has_audio_markup(field_value: str) -> bool:\n",
    "    \"\"\"æ£€æŸ¥å­—æ®µä¸­æ˜¯å¦åŒ…å«éŸ³é¢‘æ ‡è®° [sound:...]\"\"\"\n",
    "    if not field_value:\n",
    "        return False\n",
    "    return \"[sound:\" in field_value\n",
    "\n",
    "def re_crawl_and_upload_pronunciation(deck_name: str = DECK_NAME, sleep: float = SLEEP_TIME, skip_first_n: int = SKIP_FIRST_N):\n",
    "    \"\"\"\n",
    "    ä¸º Media ç‰Œç»„ä¸­ç¼ºå°‘è¯»éŸ³çš„å¡ç‰‡é‡æ–°çˆ¬è™«å¹¶ä¸Šä¼  mp3 å‘éŸ³\n",
    "    \n",
    "    Args:\n",
    "        deck_name: ç‰Œç»„åç§°ï¼Œé»˜è®¤ä¸º \"Media\"\n",
    "        sleep: çˆ¬è™«è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "        skip_first_n: è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼Œé»˜è®¤ä¸º 0ï¼ˆä¸è·³è¿‡ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"å¼€å§‹ä¸ºç‰Œç»„ '{deck_name}' ä¸­ç¼ºå°‘è¯»éŸ³çš„å¡ç‰‡é‡æ–°çˆ¬è™«å¹¶ä¸Šä¼  mp3...\")\n",
    "    if skip_first_n > 0:\n",
    "        print(f\"âš ï¸  å°†è·³è¿‡å‰ {skip_first_n} ä¸ªç¬”è®°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. è·å–ç‰Œç»„ä¸­æ‰€æœ‰ç¬”è®°\n",
    "    query = f'deck:\"{deck_name}\"'\n",
    "    note_ids = invoke_with_retry(\"findNotes\", query=query).get(\"result\", [])\n",
    "    \n",
    "    if not note_ids:\n",
    "        print(f\"âŒ ç‰Œç»„ '{deck_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬”è®°\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "    if skip_first_n > 0:\n",
    "        remaining = len(note_ids) - skip_first_n\n",
    "        print(f\"ğŸ“Š å°†å¤„ç† {remaining} ä¸ªç¬”è®°ï¼ˆè·³è¿‡å‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 2. è·å–æ‰€æœ‰ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯\n",
    "    notes_info = invoke_with_retry(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skip_count = 0\n",
    "    skipped_by_user = 0\n",
    "    already_has_audio_count = 0\n",
    "    \n",
    "    # 3. éå†æ¯ä¸ªç¬”è®°\n",
    "    for i, note_info in enumerate(notes_info, 1):\n",
    "        # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        if i <= skip_first_n:\n",
    "            skipped_by_user += 1\n",
    "            continue\n",
    "        \n",
    "        note_id = note_info.get(\"noteId\")\n",
    "        fields = note_info.get(\"fields\", {})\n",
    "        word_field = fields.get(\"Word\", {})\n",
    "        word = word_field.get(\"value\", \"\").strip() if word_field else \"\"\n",
    "        \n",
    "        if not word:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šç¬”è®° ID {note_id} æ²¡æœ‰ Word å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "        \n",
    "        try:\n",
    "            # 4. æ£€æŸ¥æ˜¯å¦å·²æœ‰éŸ³é¢‘\n",
    "            pronunciation_field = fields.get(\"Pronunciation\", {})\n",
    "            pronunciation_value = pronunciation_field.get(\"value\", \"\") if pronunciation_field else \"\"\n",
    "            pos_definitions_field = fields.get(\"POS_Definitions\", {})\n",
    "            pos_definitions_value = pos_definitions_field.get(\"value\", \"\") if pos_definitions_field else \"\"\n",
    "            \n",
    "            has_pronunciation_audio = has_audio_markup(pronunciation_value)\n",
    "            has_pos_audio = has_audio_markup(pos_definitions_value)\n",
    "            \n",
    "            if has_pronunciation_audio and has_pos_audio:\n",
    "                print(f\"  âœ… å·²æœ‰éŸ³é¢‘ï¼Œè·³è¿‡\")\n",
    "                already_has_audio_count += 1\n",
    "                continue\n",
    "            \n",
    "            # 5. é‡æ–°çˆ¬è™«è·å–å•è¯ä¿¡æ¯\n",
    "            print(f\"  ğŸ”„ æ­£åœ¨ä» Cambridge Dictionary è·å–ä¿¡æ¯...\")\n",
    "            word_info = get_word_info_by_word(word, sleep=sleep)\n",
    "            \n",
    "            if not word_info or not word_info.get(\"partOfSpeech\"):\n",
    "                print(f\"  âš ï¸  æœªè·å–åˆ°å•è¯ä¿¡æ¯ï¼Œè·³è¿‡\")\n",
    "                fail_count += 1\n",
    "                continue\n",
    "            \n",
    "            # 6. è·å–å‘éŸ³éŸ³é¢‘\n",
    "            audio_markup = ensure_pronunciation_audio(word_info)\n",
    "            \n",
    "            if not audio_markup:\n",
    "                print(f\"  âš ï¸  æœªè·å–åˆ°å‘éŸ³éŸ³é¢‘ï¼Œè·³è¿‡\")\n",
    "                fail_count += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  âœ… è·å–åˆ°å‘éŸ³éŸ³é¢‘: {audio_markup}\")\n",
    "            \n",
    "            # 7. æ›´æ–°å­—æ®µ\n",
    "            update_fields = {}\n",
    "            \n",
    "            # æ›´æ–° Pronunciation å­—æ®µ\n",
    "            if not has_pronunciation_audio:\n",
    "                if pronunciation_value:\n",
    "                    update_fields[\"Pronunciation\"] = f\"{audio_markup}\\n{pronunciation_value}\"\n",
    "                else:\n",
    "                    update_fields[\"Pronunciation\"] = audio_markup\n",
    "                print(f\"  âœ… Pronunciation å­—æ®µå·²æ›´æ–°\")\n",
    "            \n",
    "            # æ›´æ–° POS_Definitions å­—æ®µ\n",
    "            if not has_pos_audio:\n",
    "                if pos_definitions_value:\n",
    "                    update_fields[\"POS_Definitions\"] = f\"{audio_markup}\\n{pos_definitions_value}\"\n",
    "                else:\n",
    "                    update_fields[\"POS_Definitions\"] = audio_markup\n",
    "                print(f\"  âœ… POS_Definitions å­—æ®µå·²æ›´æ–°\")\n",
    "            \n",
    "            # 8. æ›´æ–°ç¬”è®°\n",
    "            if update_fields:\n",
    "                try:\n",
    "                    result = invoke_with_retry(\"updateNoteFields\", note={\"id\": note_id, \"fields\": update_fields})\n",
    "                    \n",
    "                    if result and not result.get(\"error\"):\n",
    "                        print(f\"  âœ… ç¬”è®°æ›´æ–°æˆåŠŸ\")\n",
    "                        success_count += 1\n",
    "                    else:\n",
    "                        error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\") if result else \"æ— å“åº”\"\n",
    "                        print(f\"  âŒ æ›´æ–°å¤±è´¥: {error_msg}\")\n",
    "                        fail_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ æ›´æ–°å¤±è´¥ï¼ˆè¿æ¥é—®é¢˜ï¼‰: {e}\")\n",
    "                    fail_count += 1\n",
    "            else:\n",
    "                print(f\"  âš ï¸  æ²¡æœ‰éœ€è¦æ›´æ–°çš„å­—æ®µ\")\n",
    "                skip_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            fail_count += 1\n",
    "    \n",
    "    # 9. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸæ·»åŠ éŸ³é¢‘: {success_count} ä¸ª\")\n",
    "    print(f\"å·²æœ‰éŸ³é¢‘: {already_has_audio_count} ä¸ª\")\n",
    "    print(f\"å¤±è´¥: {fail_count} ä¸ª\")\n",
    "    print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "    if skipped_by_user > 0:\n",
    "        print(f\"ç”¨æˆ·è·³è¿‡: {skipped_by_user} ä¸ªï¼ˆå‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(f\"æ€»è®¡: {len(notes_info)} ä¸ª\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# æ‰§è¡Œå¤„ç†\n",
    "# ä¿®æ”¹ SKIP_FIRST_N çš„å€¼æ¥è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼ˆä¾‹å¦‚ï¼šSKIP_FIRST_N = 50 è¡¨ç¤ºè·³è¿‡å‰ 50 ä¸ªï¼‰\n",
    "if __name__ == \"__main__\" or True:  # åœ¨ notebook ä¸­æ€»æ˜¯æ‰§è¡Œ\n",
    "    re_crawl_and_upload_pronunciation(deck_name=DECK_NAME, sleep=SLEEP_TIME, skip_first_n=SKIP_FIRST_N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d57e2c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ä¿®å¤ Media ç‰Œç»„ä¸­å¤±æ•ˆçš„ [sound:...] éŸ³é¢‘æ ‡è®°\n",
    "- æŸ¥æ‰¾æ‰€æœ‰ Media ç‰Œç»„ä¸­çš„ç¬”è®°\n",
    "- ä» Pronunciation å’Œ POS_Definitions å­—æ®µä¸­æå– [sound:...] æ ‡è®°\n",
    "- æ£€æŸ¥è¿™äº›éŸ³é¢‘æ–‡ä»¶æ˜¯å¦çœŸçš„å­˜åœ¨ï¼ˆé€šè¿‡é‡æ–°ä¸Šä¼ æµ‹è¯•ï¼‰\n",
    "- å¦‚æœå¤±æ•ˆï¼Œé‡æ–°çˆ¬è™«è·å–å•è¯ä¿¡æ¯ï¼Œä¸‹è½½éŸ³é¢‘å¹¶ä¸Šä¼ \n",
    "- æ›´æ–°å­—æ®µä¸­çš„éŸ³é¢‘æ ‡è®°\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import time\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„ï¼ˆcode ç›®å½•ï¼‰\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke, ensure_pronunciation_audio\n",
    "from dictionary.dict import get_word_info_by_word\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SLEEP_TIME = 0.5  # çˆ¬è™«é—´éš”ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "\n",
    "def invoke_with_retry(action: str, retry_times: int = 3, retry_delay: float = 2, **params):\n",
    "    \"\"\"å¸¦é‡è¯•æœºåˆ¶çš„ Anki invoke åŒ…è£…å‡½æ•°\"\"\"\n",
    "    last_error = None\n",
    "    \n",
    "    for attempt in range(retry_times):\n",
    "        try:\n",
    "            result = anki_invoke(action, **params)\n",
    "            if result and result.get(\"error\"):\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\")\n",
    "                if attempt < retry_times - 1:\n",
    "                    print(f\"  âš ï¸  Anki è¿”å›é”™è¯¯: {error_msg}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                    time.sleep(retry_delay)\n",
    "                    continue\n",
    "                else:\n",
    "                    last_error = error_msg\n",
    "            else:\n",
    "                return result\n",
    "        except Exception as e:\n",
    "            last_error = str(e)\n",
    "            if attempt < retry_times - 1:\n",
    "                print(f\"  âš ï¸  Anki è¿æ¥å¤±è´¥: {e}, å°†åœ¨ {retry_delay} ç§’åé‡è¯•...\")\n",
    "                time.sleep(retry_delay)\n",
    "            else:\n",
    "                raise\n",
    "    \n",
    "    if last_error:\n",
    "        raise Exception(f\"Anki æ“ä½œå¤±è´¥: {last_error}\")\n",
    "    return result\n",
    "\n",
    "def extract_sound_markups(field_value: str) -> list:\n",
    "    \"\"\"ä»å­—æ®µä¸­æå–æ‰€æœ‰ [sound:...] æ ‡è®°\"\"\"\n",
    "    if not field_value:\n",
    "        return []\n",
    "    \n",
    "    pattern = r'\\[sound:([^\\]]+)\\]'\n",
    "    matches = re.findall(pattern, field_value)\n",
    "    return matches\n",
    "\n",
    "def fix_invalid_audio_markups(deck_name: str = DECK_NAME, sleep: float = SLEEP_TIME, skip_first_n: int = SKIP_FIRST_N):\n",
    "    \"\"\"\n",
    "    ä¿®å¤ Media ç‰Œç»„ä¸­å¤±æ•ˆçš„ [sound:...] éŸ³é¢‘æ ‡è®°\n",
    "    \n",
    "    Args:\n",
    "        deck_name: ç‰Œç»„åç§°ï¼Œé»˜è®¤ä¸º \"Media\"\n",
    "        sleep: çˆ¬è™«è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰ï¼Œé¿å…è¯·æ±‚è¿‡å¿«\n",
    "        skip_first_n: è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼Œé»˜è®¤ä¸º 0ï¼ˆä¸è·³è¿‡ï¼‰\n",
    "    \"\"\"\n",
    "    print(f\"å¼€å§‹ä¿®å¤ç‰Œç»„ '{deck_name}' ä¸­å¤±æ•ˆçš„éŸ³é¢‘æ ‡è®°...\")\n",
    "    if skip_first_n > 0:\n",
    "        print(f\"âš ï¸  å°†è·³è¿‡å‰ {skip_first_n} ä¸ªç¬”è®°\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 1. è·å–ç‰Œç»„ä¸­æ‰€æœ‰ç¬”è®°\n",
    "    query = f'deck:\"{deck_name}\"'\n",
    "    note_ids = invoke_with_retry(\"findNotes\", query=query).get(\"result\", [])\n",
    "    \n",
    "    if not note_ids:\n",
    "        print(f\"âŒ ç‰Œç»„ '{deck_name}' ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ç¬”è®°\")\n",
    "        return\n",
    "    \n",
    "    print(f\"âœ… æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "    if skip_first_n > 0:\n",
    "        remaining = len(note_ids) - skip_first_n\n",
    "        print(f\"ğŸ“Š å°†å¤„ç† {remaining} ä¸ªç¬”è®°ï¼ˆè·³è¿‡å‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # 2. è·å–æ‰€æœ‰ç¬”è®°çš„è¯¦ç»†ä¿¡æ¯\n",
    "    notes_info = invoke_with_retry(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "    \n",
    "    success_count = 0\n",
    "    fail_count = 0\n",
    "    skip_count = 0\n",
    "    skipped_by_user = 0\n",
    "    no_audio_markup_count = 0\n",
    "    fixed_count = 0\n",
    "    \n",
    "    # 3. éå†æ¯ä¸ªç¬”è®°\n",
    "    for i, note_info in enumerate(notes_info, 1):\n",
    "        # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "        if i <= skip_first_n:\n",
    "            skipped_by_user += 1\n",
    "            continue\n",
    "        \n",
    "        note_id = note_info.get(\"noteId\")\n",
    "        fields = note_info.get(\"fields\", {})\n",
    "        word_field = fields.get(\"Word\", {})\n",
    "        word = word_field.get(\"value\", \"\").strip() if word_field else \"\"\n",
    "        \n",
    "        if not word:\n",
    "            print(f\"\\n[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šç¬”è®° ID {note_id} æ²¡æœ‰ Word å­—æ®µ\")\n",
    "            skip_count += 1\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "        \n",
    "        try:\n",
    "            # 4. æå–æ‰€æœ‰éŸ³é¢‘æ ‡è®°\n",
    "            pronunciation_field = fields.get(\"Pronunciation\", {})\n",
    "            pronunciation_value = pronunciation_field.get(\"value\", \"\") if pronunciation_field else \"\"\n",
    "            pos_definitions_field = fields.get(\"POS_Definitions\", {})\n",
    "            pos_definitions_value = pos_definitions_field.get(\"value\", \"\") if pos_definitions_field else \"\"\n",
    "            \n",
    "            pronunciation_sounds = extract_sound_markups(pronunciation_value)\n",
    "            pos_sounds = extract_sound_markups(pos_definitions_value)\n",
    "            all_sounds = list(set(pronunciation_sounds + pos_sounds))\n",
    "            \n",
    "            if not all_sounds:\n",
    "                print(f\"  âš ï¸  æœªæ‰¾åˆ°éŸ³é¢‘æ ‡è®°ï¼Œè·³è¿‡\")\n",
    "                no_audio_markup_count += 1\n",
    "                skip_count += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  ğŸ“‹ æ‰¾åˆ° {len(all_sounds)} ä¸ªéŸ³é¢‘æ ‡è®°: {', '.join(all_sounds)}\")\n",
    "            \n",
    "            # 5. é‡æ–°çˆ¬è™«è·å–å•è¯ä¿¡æ¯å¹¶ä¸‹è½½éŸ³é¢‘\n",
    "            print(f\"  ğŸ”„ æ­£åœ¨ä» Cambridge Dictionary é‡æ–°è·å–éŸ³é¢‘...\")\n",
    "            word_info = get_word_info_by_word(word, sleep=sleep)\n",
    "            \n",
    "            if not word_info or not word_info.get(\"partOfSpeech\"):\n",
    "                print(f\"  âš ï¸  æœªè·å–åˆ°å•è¯ä¿¡æ¯ï¼Œè·³è¿‡\")\n",
    "                fail_count += 1\n",
    "                continue\n",
    "            \n",
    "            # 6. è·å–æ–°çš„å‘éŸ³éŸ³é¢‘\n",
    "            new_audio_markup = ensure_pronunciation_audio(word_info)\n",
    "            \n",
    "            if not new_audio_markup:\n",
    "                print(f\"  âš ï¸  æœªè·å–åˆ°å‘éŸ³éŸ³é¢‘ï¼Œè·³è¿‡\")\n",
    "                fail_count += 1\n",
    "                continue\n",
    "            \n",
    "            print(f\"  âœ… è·å–åˆ°æ–°çš„å‘éŸ³éŸ³é¢‘: {new_audio_markup}\")\n",
    "            \n",
    "            # 7. æ£€æŸ¥æ˜¯å¦éœ€è¦æ›´æ–°å­—æ®µ\n",
    "            update_fields = {}\n",
    "            \n",
    "            # æ£€æŸ¥ Pronunciation å­—æ®µ\n",
    "            if pronunciation_sounds:\n",
    "                # å¦‚æœå­—æ®µä¸­æœ‰éŸ³é¢‘æ ‡è®°ï¼Œä½†å¯èƒ½å¤±æ•ˆï¼Œç”¨æ–°çš„æ›¿æ¢\n",
    "                # æ›¿æ¢æ‰€æœ‰æ—§çš„éŸ³é¢‘æ ‡è®°ä¸ºæ–°çš„\n",
    "                new_pronunciation = pronunciation_value\n",
    "                pronunciation_updated = False\n",
    "                for old_sound in pronunciation_sounds:\n",
    "                    old_markup = f\"[sound:{old_sound}]\"\n",
    "                    if old_markup in new_pronunciation:\n",
    "                        new_pronunciation = new_pronunciation.replace(old_markup, new_audio_markup, 1)\n",
    "                        pronunciation_updated = True\n",
    "                \n",
    "                if pronunciation_updated:\n",
    "                    update_fields[\"Pronunciation\"] = new_pronunciation\n",
    "                    print(f\"  âœ… Pronunciation å­—æ®µå°†æ›´æ–°ï¼ˆæ›¿æ¢å¤±æ•ˆçš„éŸ³é¢‘æ ‡è®°ï¼‰\")\n",
    "            elif not has_audio_markup(pronunciation_value):\n",
    "                # å¦‚æœå­—æ®µä¸­æ²¡æœ‰éŸ³é¢‘æ ‡è®°ï¼Œæ·»åŠ æ–°çš„\n",
    "                if pronunciation_value:\n",
    "                    update_fields[\"Pronunciation\"] = f\"{new_audio_markup}\\n{pronunciation_value}\"\n",
    "                else:\n",
    "                    update_fields[\"Pronunciation\"] = new_audio_markup\n",
    "                print(f\"  âœ… Pronunciation å­—æ®µå°†æ·»åŠ éŸ³é¢‘\")\n",
    "            \n",
    "            # æ£€æŸ¥ POS_Definitions å­—æ®µ\n",
    "            if pos_sounds:\n",
    "                # å¦‚æœå­—æ®µä¸­æœ‰éŸ³é¢‘æ ‡è®°ï¼Œä½†å¯èƒ½å¤±æ•ˆï¼Œç”¨æ–°çš„æ›¿æ¢\n",
    "                new_pos_definitions = pos_definitions_value\n",
    "                pos_updated = False\n",
    "                for old_sound in pos_sounds:\n",
    "                    old_markup = f\"[sound:{old_sound}]\"\n",
    "                    if old_markup in new_pos_definitions:\n",
    "                        new_pos_definitions = new_pos_definitions.replace(old_markup, new_audio_markup, 1)\n",
    "                        pos_updated = True\n",
    "                \n",
    "                if pos_updated:\n",
    "                    update_fields[\"POS_Definitions\"] = new_pos_definitions\n",
    "                    print(f\"  âœ… POS_Definitions å­—æ®µå°†æ›´æ–°ï¼ˆæ›¿æ¢å¤±æ•ˆçš„éŸ³é¢‘æ ‡è®°ï¼‰\")\n",
    "            elif not has_audio_markup(pos_definitions_value):\n",
    "                # å¦‚æœå­—æ®µä¸­æ²¡æœ‰éŸ³é¢‘æ ‡è®°ï¼Œæ·»åŠ æ–°çš„\n",
    "                if pos_definitions_value:\n",
    "                    update_fields[\"POS_Definitions\"] = f\"{new_audio_markup}\\n{pos_definitions_value}\"\n",
    "                else:\n",
    "                    update_fields[\"POS_Definitions\"] = new_audio_markup\n",
    "                print(f\"  âœ… POS_Definitions å­—æ®µå°†æ·»åŠ éŸ³é¢‘\")\n",
    "            \n",
    "            # 8. æ›´æ–°ç¬”è®°\n",
    "            if update_fields:\n",
    "                try:\n",
    "                    result = invoke_with_retry(\"updateNoteFields\", note={\"id\": note_id, \"fields\": update_fields})\n",
    "                    \n",
    "                    if result and not result.get(\"error\"):\n",
    "                        print(f\"  âœ… ç¬”è®°æ›´æ–°æˆåŠŸ\")\n",
    "                        success_count += 1\n",
    "                        fixed_count += 1\n",
    "                    else:\n",
    "                        error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\") if result else \"æ— å“åº”\"\n",
    "                        print(f\"  âŒ æ›´æ–°å¤±è´¥: {error_msg}\")\n",
    "                        fail_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  âŒ æ›´æ–°å¤±è´¥ï¼ˆè¿æ¥é—®é¢˜ï¼‰: {e}\")\n",
    "                    fail_count += 1\n",
    "            else:\n",
    "                print(f\"  âš ï¸  éŸ³é¢‘æ ‡è®°æ­£å¸¸ï¼Œæ— éœ€æ›´æ–°\")\n",
    "                skip_count += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ å¤„ç†å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            fail_count += 1\n",
    "    \n",
    "    # 9. è¾“å‡ºç»Ÿè®¡ä¿¡æ¯\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"å¤„ç†å®Œæˆï¼\")\n",
    "    print(f\"æˆåŠŸä¿®å¤: {fixed_count} ä¸ª\")\n",
    "    print(f\"æˆåŠŸæ·»åŠ : {success_count - fixed_count} ä¸ª\")\n",
    "    print(f\"å¤±è´¥: {fail_count} ä¸ª\")\n",
    "    print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "    print(f\"æ— éŸ³é¢‘æ ‡è®°: {no_audio_markup_count} ä¸ª\")\n",
    "    if skipped_by_user > 0:\n",
    "        print(f\"ç”¨æˆ·è·³è¿‡: {skipped_by_user} ä¸ªï¼ˆå‰ {skip_first_n} ä¸ªï¼‰\")\n",
    "    print(f\"æ€»è®¡: {len(notes_info)} ä¸ª\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "def has_audio_markup(field_value: str) -> bool:\n",
    "    \"\"\"æ£€æŸ¥å­—æ®µä¸­æ˜¯å¦åŒ…å«éŸ³é¢‘æ ‡è®° [sound:...]\"\"\"\n",
    "    if not field_value:\n",
    "        return False\n",
    "    return \"[sound:\" in field_value\n",
    "\n",
    "# æ‰§è¡Œå¤„ç†\n",
    "# ä¿®æ”¹ SKIP_FIRST_N çš„å€¼æ¥è·³è¿‡å‰ n ä¸ªç¬”è®°ï¼ˆä¾‹å¦‚ï¼šSKIP_FIRST_N = 50 è¡¨ç¤ºè·³è¿‡å‰ 50 ä¸ªï¼‰\n",
    "if __name__ == \"__main__\" or True:  # åœ¨ notebook ä¸­æ€»æ˜¯æ‰§è¡Œ\n",
    "    fix_invalid_audio_markups(deck_name=DECK_NAME, sleep=SLEEP_TIME, skip_first_n=SKIP_FIRST_N)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55761e64",
   "metadata": {},
   "source": [
    "# éå†å¹¶åˆ é™¤ç›¸åº”å­—æ®µçš„éƒ¨åˆ†å†…å®¹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c29dbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "éå† Media ç‰Œç»„ï¼Œåˆ é™¤å­—æ®µä¸­çš„æŒ‡å®šæ–‡æœ¬\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "FIELD_NAME = \"Examples\"  # è¦ä¿®æ”¹çš„å­—æ®µå\n",
    "TEXT_TO_DELETE = \"æ–°ä¾‹å¥\"  # è¦åˆ é™¤çš„æ–‡æœ¬å†…å®¹\n",
    "\n",
    "# 1. è·å–æ‰€æœ‰ç¬”è®°\n",
    "query = f'deck:\"{DECK_NAME}\"'\n",
    "note_ids = anki_invoke(\"findNotes\", query=query).get(\"result\", [])\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "\n",
    "# 2. è·å–ç¬”è®°è¯¦æƒ…\n",
    "notes_info = anki_invoke(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "\n",
    "# 3. éå†å¹¶æ›´æ–°\n",
    "for i, note in enumerate(notes_info, 1):\n",
    "    note_id = note.get(\"noteId\")\n",
    "    fields = note.get(\"fields\", {})\n",
    "    word = fields.get(\"Word\", {}).get(\"value\", \"\").strip()\n",
    "    field_value = fields.get(FIELD_NAME, {}).get(\"value\", \"\")\n",
    "    \n",
    "    if not field_value:\n",
    "        continue\n",
    "    \n",
    "    # åˆ é™¤æŒ‡å®šæ–‡æœ¬\n",
    "    new_value = field_value.replace(TEXT_TO_DELETE, \"\")\n",
    "    \n",
    "    # å¦‚æœæœ‰å˜åŒ–ï¼Œæ›´æ–°\n",
    "    if new_value != field_value:\n",
    "        print(f\"[{i}/{len(notes_info)}] æ›´æ–°: {word}\")\n",
    "        anki_invoke(\"updateNoteFields\", note={\"id\": note_id, \"fields\": {FIELD_NAME: new_value}})\n",
    "    else:\n",
    "        print(f\"[{i}/{len(notes_info)}] è·³è¿‡: {word} (æœªæ‰¾åˆ°è¦åˆ é™¤çš„æ–‡æœ¬)\")\n",
    "\n",
    "print(\"å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f95b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "æ›´æ–° Media ç‰Œç»„ä¸­çš„ Blanked_Examples å’Œ Definition å­—æ®µ\n",
    "1. ä¸º Blanked_Examples ä¸­çš„æ¯ä¸ª example æ·»åŠ  meta ä¿¡æ¯ï¼ˆbook_name å’Œ timestampï¼‰\n",
    "2. ç¡®ä¿ Definition å­—æ®µåŒ…å«è¯æ€§ä¿¡æ¯\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "import html\n",
    "\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke, build_html_from_word_info\n",
    "from dictionary.dict import get_word_info_by_word\n",
    "from movie.import_to_anki import format_timestamp\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "SLEEP_TIME = 0.5  # çˆ¬è™«é—´éš”\n",
    "\n",
    "def extract_book_name_from_examples(examples_html: str) -> str:\n",
    "    \"\"\"ä» Examples å­—æ®µä¸­æå– book_name\"\"\"\n",
    "    if not examples_html:\n",
    "        return \"\"\n",
    "    \n",
    "    # åŒ¹é…æ ¼å¼ï¼š â€” ã€Šä¹¦åã€‹\n",
    "    pattern = r'â€”\\s*ã€Š([^ã€‹]+)ã€‹'\n",
    "    matches = re.findall(pattern, examples_html)\n",
    "    if matches:\n",
    "        return matches[0]  # è¿”å›ç¬¬ä¸€ä¸ªåŒ¹é…çš„ä¹¦å\n",
    "    \n",
    "    return \"\"\n",
    "\n",
    "def extract_meta_from_example_div(example_div: str) -> tuple:\n",
    "    \"\"\"ä» example div ä¸­æå– book_name å’Œ timestamp\"\"\"\n",
    "    book_name = \"\"\n",
    "    timestamp = \"\"\n",
    "    \n",
    "    # æå–ä¹¦å\n",
    "    book_match = re.search(r'â€”\\s*ã€Š([^ã€‹]+)ã€‹', example_div)\n",
    "    if book_match:\n",
    "        book_name = book_match.group(1)\n",
    "    \n",
    "    # æå–æ—¶é—´æˆ³ï¼ˆæ ¼å¼ï¼š0:01:23:45ï¼‰\n",
    "    timestamp_match = re.search(r'(\\d+:\\d{2}:\\d{2}:\\d{2})', example_div)\n",
    "    if timestamp_match:\n",
    "        timestamp = timestamp_match.group(1)\n",
    "    \n",
    "    return book_name, timestamp\n",
    "\n",
    "def update_blanked_examples_with_meta(blanked_examples_html: str, examples_html: str) -> str:\n",
    "    \"\"\"ä¸º Blanked_Examples ä¸­çš„æ¯ä¸ª example æ·»åŠ  meta ä¿¡æ¯\"\"\"\n",
    "    if not blanked_examples_html:\n",
    "        return blanked_examples_html\n",
    "    \n",
    "    # ä» Examples å­—æ®µè·å–é»˜è®¤çš„ book_name\n",
    "    default_book_name = extract_book_name_from_examples(examples_html)\n",
    "    \n",
    "    # åˆ†å‰²æ‰€æœ‰çš„ example div\n",
    "    example_pattern = r'(<div class=\\'example\\'>.*?</div>)'\n",
    "    parts = re.split(example_pattern, blanked_examples_html, flags=re.DOTALL)\n",
    "    \n",
    "    updated_parts = []\n",
    "    for part in parts:\n",
    "        if '<div class=\\'example\\'>' in part:\n",
    "            # è¿™æ˜¯ä¸€ä¸ª example div\n",
    "            # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ meta ä¿¡æ¯\n",
    "            if '<div class=\\'example-meta\\'>' in part:\n",
    "                # å·²ç»æœ‰ metaï¼Œä¿æŒä¸å˜\n",
    "                updated_parts.append(part)\n",
    "            else:\n",
    "                # æ²¡æœ‰ metaï¼Œéœ€è¦æ·»åŠ \n",
    "                # å°è¯•ä»å¯¹åº”çš„ Examples å­—æ®µä¸­æå– meta\n",
    "                book_name, timestamp = extract_meta_from_example_div(examples_html)\n",
    "                if not book_name:\n",
    "                    book_name = default_book_name or \"Movie\"\n",
    "                \n",
    "                # æ ¼å¼åŒ–æ—¶é—´æˆ³\n",
    "                formatted_timestamp = format_timestamp(timestamp) if timestamp else \"\"\n",
    "                meta_text = f\" â€” ã€Š{html.escape(book_name)}ã€‹\"\n",
    "                if formatted_timestamp:\n",
    "                    meta_text += f\" {formatted_timestamp}\"\n",
    "                \n",
    "                # åœ¨ example-text åé¢æ·»åŠ  meta\n",
    "                updated_part = part.replace(\n",
    "                    '</div></div>',\n",
    "                    f'</div><div class=\\'example-meta\\'>{meta_text}</div></div>'\n",
    "                )\n",
    "                updated_parts.append(updated_part)\n",
    "        else:\n",
    "            # ä¸æ˜¯ example divï¼Œç›´æ¥ä¿ç•™\n",
    "            updated_parts.append(part)\n",
    "    \n",
    "    return ''.join(updated_parts)\n",
    "\n",
    "def ensure_definition_has_pos(definition_html: str, word: str) -> str:\n",
    "    \"\"\"ç¡®ä¿ Definition å­—æ®µåŒ…å«è¯æ€§ä¿¡æ¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™é‡æ–°è·å–\"\"\"\n",
    "    if not definition_html:\n",
    "        # å¦‚æœ Definition ä¸ºç©ºï¼Œé‡æ–°è·å–\n",
    "        word_info = get_word_info_by_word(word, sleep=SLEEP_TIME)\n",
    "        if word_info and word_info.get(\"partOfSpeech\"):\n",
    "            fields = build_html_from_word_info(word_info)\n",
    "            return fields.get(\"Definition\", \"\")\n",
    "        return \"\"\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯æ€§æ ‡é¢˜ï¼ˆpos-title classï¼‰\n",
    "    if '<div class=\\'pos-title\\'>' in definition_html:\n",
    "        # å·²ç»æœ‰è¯æ€§ä¿¡æ¯\n",
    "        return definition_html\n",
    "    \n",
    "    # æ²¡æœ‰è¯æ€§ä¿¡æ¯ï¼Œé‡æ–°è·å–\n",
    "    word_info = get_word_info_by_word(word, sleep=SLEEP_TIME)\n",
    "    if word_info and word_info.get(\"partOfSpeech\"):\n",
    "        fields = build_html_from_word_info(word_info)\n",
    "        new_definition = fields.get(\"Definition\", \"\")\n",
    "        if new_definition:\n",
    "            return new_definition\n",
    "    \n",
    "    # å¦‚æœè·å–å¤±è´¥ï¼Œè¿”å›åŸå†…å®¹\n",
    "    return definition_html\n",
    "\n",
    "# 1. è·å–æ‰€æœ‰ç¬”è®°\n",
    "query = f'deck:\"{DECK_NAME}\"'\n",
    "note_ids = anki_invoke(\"findNotes\", query=query).get(\"result\", [])\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2. è·å–ç¬”è®°è¯¦æƒ…\n",
    "notes_info = anki_invoke(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "\n",
    "updated_blanked = 0\n",
    "updated_definition = 0\n",
    "skip_count = 0\n",
    "\n",
    "# 3. éå†å¹¶æ›´æ–°\n",
    "for i, note in enumerate(notes_info, 1):\n",
    "    if i <= SKIP_FIRST_N:\n",
    "        continue\n",
    "    \n",
    "    note_id = note.get(\"noteId\")\n",
    "    fields = note.get(\"fields\", {})\n",
    "    word = fields.get(\"Word\", {}).get(\"value\", \"\").strip()\n",
    "    \n",
    "    if not word:\n",
    "        print(f\"[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šæ²¡æœ‰ Word å­—æ®µ\")\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "    \n",
    "    update_fields = {}\n",
    "    \n",
    "    # æ›´æ–° Blanked_Examples\n",
    "    blanked_examples = fields.get(\"Blanked_Examples\", {}).get(\"value\", \"\")\n",
    "    examples = fields.get(\"Examples\", {}).get(\"value\", \"\")\n",
    "    \n",
    "    if blanked_examples:\n",
    "        updated_blanked_html = update_blanked_examples_with_meta(blanked_examples, examples)\n",
    "        if updated_blanked_html != blanked_examples:\n",
    "            update_fields[\"Blanked_Examples\"] = updated_blanked_html\n",
    "            print(f\"  âœ… Blanked_Examples å·²æ›´æ–°ï¼ˆæ·»åŠ  meta ä¿¡æ¯ï¼‰\")\n",
    "            updated_blanked += 1\n",
    "    \n",
    "    # æ›´æ–° Definition\n",
    "    definition = fields.get(\"Definition\", {}).get(\"value\", \"\")\n",
    "    updated_definition_html = ensure_definition_has_pos(definition, word)\n",
    "    if updated_definition_html != definition:\n",
    "        update_fields[\"Definition\"] = updated_definition_html\n",
    "        print(f\"  âœ… Definition å·²æ›´æ–°ï¼ˆæ·»åŠ è¯æ€§ä¿¡æ¯ï¼‰\")\n",
    "        updated_definition += 1\n",
    "    \n",
    "    # å¦‚æœæœ‰æ›´æ–°ï¼Œä¿å­˜\n",
    "    if update_fields:\n",
    "        try:\n",
    "            result = anki_invoke(\"updateNoteFields\", note={\"id\": note_id, \"fields\": update_fields})\n",
    "            if result and not result.get(\"error\"):\n",
    "                print(f\"  âœ… ç¬”è®°æ›´æ–°æˆåŠŸ\")\n",
    "            else:\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\") if result else \"æ— å“åº”\"\n",
    "                print(f\"  âŒ æ›´æ–°å¤±è´¥: {error_msg}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æ›´æ–°å¼‚å¸¸: {e}\")\n",
    "    else:\n",
    "        print(f\"  â­ï¸  æ— éœ€æ›´æ–°\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"æ›´æ–° Blanked_Examples: {updated_blanked} ä¸ª\")\n",
    "print(f\"æ›´æ–° Definition: {updated_definition} ä¸ª\")\n",
    "print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25328b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f0875d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ‰¾åˆ° 414 ä¸ªç¬”è®°\n",
      "============================================================\n",
      "\n",
      "[1/414] å¤„ç†å•è¯: twilight\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[2/414] å¤„ç†å•è¯: encapsulation\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[3/414] å¤„ç†å•è¯: transcend\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[4/414] å¤„ç†å•è¯: vest\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[5/414] å¤„ç†å•è¯: clipboard\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[6/414] å¤„ç†å•è¯: holocaust\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[7/414] å¤„ç†å•è¯: fission\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[8/414] å¤„ç†å•è¯: Armageddon\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[9/414] å¤„ç†å•è¯: remnant\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[10/414] å¤„ç†å•è¯: detritus\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[11/414] å¤„ç†å•è¯: prominent\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[12/414] å¤„ç†å•è¯: parachute\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[13/414] å¤„ç†å•è¯: bungee\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[14/414] å¤„ç†å•è¯: chitchat\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[15/414] å¤„ç†å•è¯: deduction\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[16/414] å¤„ç†å•è¯: masculine\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[17/414] å¤„ç†å•è¯: oligarch\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[18/414] å¤„ç†å•è¯: plutonium\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[19/414] å¤„ç†å•è¯: protagonist\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[20/414] å¤„ç†å•è¯: daisy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[21/414] å¤„ç†å•è¯: detonation\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[22/414] å¤„ç†å•è¯: Siberia\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[23/414] å¤„ç†å•è¯: estranged\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[24/414] å¤„ç†å•è¯: inflated\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[25/414] å¤„ç†å•è¯: seduction\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[26/414] å¤„ç†å•è¯: confiscate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[27/414] å¤„ç†å•è¯: embezzler\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[28/414] å¤„ç†å•è¯: auction\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[29/414] å¤„ç†å•è¯: forgery\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[30/414] å¤„ç†å•è¯: snobbery\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[31/414] å¤„ç†å•è¯: provenance\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[32/414] å¤„ç†å•è¯: irate\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[33/414] å¤„ç†å•è¯: defraud\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[34/414] å¤„ç†å•è¯: amass\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[35/414] å¤„ç†å•è¯: ashore\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[36/414] å¤„ç†å•è¯: contrite\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[37/414] å¤„ç†å•è¯: envy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[38/414] å¤„ç†å•è¯: redemption\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[39/414] å¤„ç†å•è¯: lava\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[40/414] å¤„ç†å•è¯: haven\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[41/414] å¤„ç†å•è¯: out of your depth\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[42/414] å¤„ç†å•è¯: high-visibility\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[43/414] å¤„ç†å•è¯: get ahead of yourself\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[44/414] å¤„ç†å•è¯: sorta\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[45/414] å¤„ç†å•è¯: tarmac\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[46/414] å¤„ç†å•è¯: precaution\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[47/414] å¤„ç†å•è¯: sprinkler\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[48/414] å¤„ç†å•è¯: suffocate\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[49/414] å¤„ç†å•è¯: blimey\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[50/414] å¤„ç†å•è¯: hydraulic\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[51/414] å¤„ç†å•è¯: taxiway\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[52/414] å¤„ç†å•è¯: hangar\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[53/414] å¤„ç†å•è¯: extradition\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[54/414] å¤„ç†å•è¯: espresso\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[55/414] å¤„ç†å•è¯: vegetarian\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[56/414] å¤„ç†å•è¯: chronology\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[57/414] å¤„ç†å•è¯: antagonist\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[58/414] å¤„ç†å•è¯: turnstiler\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[59/414] å¤„ç†å•è¯: salmon\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[60/414] å¤„ç†å•è¯: sea bass\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[61/414] å¤„ç†å•è¯: affair\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[62/414] å¤„ç†å•è¯: windpipe\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[63/414] å¤„ç†å•è¯: gratifying\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[64/414] å¤„ç†å•è¯: trappings\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[65/414] å¤„ç†å•è¯: grubby\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[66/414] å¤„ç†å•è¯: jibe\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[67/414] å¤„ç†å•è¯: harness\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[68/414] å¤„ç†å•è¯: brittle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[69/414] å¤„ç†å•è¯: savvy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[70/414] å¤„ç†å•è¯: fissile\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[71/414] å¤„ç†å•è¯: frank\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[72/414] å¤„ç†å•è¯: convoy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[73/414] å¤„ç†å•è¯: ambush\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[74/414] å¤„ç†å•è¯: cavalry\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[75/414] å¤„ç†å•è¯: singe\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[76/414] å¤„ç†å•è¯: salvageable\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[77/414] å¤„ç†å•è¯: collide\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[78/414] å¤„ç†å•è¯: filthy\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[79/414] å¤„ç†å•è¯: vengeful\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[80/414] å¤„ç†å•è¯: live off someone/something\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[81/414] å¤„ç†å•è¯: Estonian\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[82/414] å¤„ç†å•è¯: glove\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[83/414] å¤„ç†å•è¯: posterity\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[84/414] å¤„ç†å•è¯: pincer\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[85/414] å¤„ç†å•è¯: stash\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[86/414] å¤„ç†å•è¯: perimeter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[87/414] å¤„ç†å•è¯: impregnable\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[88/414] å¤„ç†å•è¯: cozy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[89/414] å¤„ç†å•è¯: annihilation\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[90/414] å¤„ç†å•è¯: orient\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[91/414] å¤„ç†å•è¯: vouch\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[92/414] å¤„ç†å•è¯: hypothermia\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[93/414] å¤„ç†å•è¯: gouge\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[94/414] å¤„ç†å•è¯: slit\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[95/414] å¤„ç†å•è¯: pessimistically\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[96/414] å¤„ç†å•è¯: engulf\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[97/414] å¤„ç†å•è¯: treacherous\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[98/414] å¤„ç†å•è¯: transponder\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[99/414] å¤„ç†å•è¯: obsessive\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[100/414] å¤„ç†å•è¯: inoperable\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[101/414] å¤„ç†å•è¯: pancreatic\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[102/414] å¤„ç†å•è¯: anguish\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[103/414] å¤„ç†å•è¯: backstop\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[104/414] å¤„ç†å•è¯: assuredly\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[105/414] å¤„ç†å•è¯: splinter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[106/414] å¤„ç†å•è¯: cavern\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[107/414] å¤„ç†å•è¯: defuse\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[108/414] å¤„ç†å•è¯: chopper\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[109/414] å¤„ç†å•è¯: distraction\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[110/414] å¤„ç†å•è¯: whimper\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[111/414] å¤„ç†å•è¯: vodka\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[112/414] å¤„ç†å•è¯: radioactive\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[113/414] å¤„ç†å•è¯: anonymous\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[114/414] å¤„ç†å•è¯: crystalline\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[115/414] å¤„ç†å•è¯: descendant\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[116/414] å¤„ç†å•è¯: sunscreen\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[117/414] å¤„ç†å•è¯: locksmith\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[118/414] å¤„ç†å•è¯: weave\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[119/414] å¤„ç†å•è¯: fabric\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[120/414] å¤„ç†å•è¯: tie up loose ends\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[121/414] å¤„ç†å•è¯: smuggle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[122/414] å¤„ç†å•è¯: gunpowder\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[123/414] å¤„ç†å•è¯: casing\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[124/414] å¤„ç†å•è¯: blight\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[125/414] å¤„ç†å•è¯: herbicide\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[126/414] å¤„ç†å•è¯: poltergeist\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[127/414] å¤„ç†å•è¯: turbo\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[128/414] å¤„ç†å•è¯: torch\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[129/414] å¤„ç†å•è¯: okra\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[130/414] å¤„ç†å•è¯: grind\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[131/414] å¤„ç†å•è¯: tire\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[132/414] å¤„ç†å•è¯: cliff\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[133/414] å¤„ç†å•è¯: scenario\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[134/414] å¤„ç†å•è¯: whirl\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[135/414] å¤„ç†å•è¯: reservoir\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[136/414] å¤„ç†å•è¯: flat\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[137/414] å¤„ç†å•è¯: knack\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[138/414] å¤„ç†å•è¯: waistline\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[139/414] å¤„ç†å•è¯: inseam\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[140/414] å¤„ç†å•è¯: cyst\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[141/414] å¤„ç†å•è¯: fistfight\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[142/414] å¤„ç†å•è¯: combine\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[143/414] å¤„ç†å•è¯: haywire\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[144/414] å¤„ç†å•è¯: magnetism\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[145/414] å¤„ç†å•è¯: anomaly\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[146/414] å¤„ç†å•è¯: peel away/off\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[147/414] å¤„ç†å•è¯: tractor\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[148/414] å¤„ç†å•è¯: canyon\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[149/414] å¤„ç†å•è¯: bum\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[150/414] å¤„ç†å•è¯: footsteps\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[151/414] å¤„ç†å•è¯: doozy\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[152/414] å¤„ç†å•è¯: bolt cutters\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[153/414] å¤„ç†å•è¯: grunt\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[154/414] å¤„ç†å•è¯: mow\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[155/414] å¤„ç†å•è¯: lawnmower\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[156/414] å¤„ç†å•è¯: stumble across/on/upon something/someone\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[157/414] å¤„ç†å•è¯: term\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[158/414] å¤„ç†å•è¯: assurance\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[159/414] å¤„ç†å•è¯: trunk\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[160/414] å¤„ç†å•è¯: stratosphere\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[161/414] å¤„ç†å•è¯: unshakeable\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[162/414] å¤„ç†å•è¯: ranger\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[163/414] å¤„ç†å•è¯: strait\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[164/414] å¤„ç†å•è¯: trip\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[165/414] å¤„ç†å•è¯: fly-by-wire\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[166/414] å¤„ç†å•è¯: wormhole\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[167/414] å¤„ç†å•è¯: hibernation\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[168/414] å¤„ç†å•è¯: rudimentary\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[169/414] å¤„ç†å•è¯: ping\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[170/414] å¤„ç†å•è¯: chamber\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[171/414] å¤„ç†å•è¯: centrifuge\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[172/414] å¤„ç†å•è¯: fertilize\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[173/414] å¤„ç†å•è¯: incubate\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[174/414] å¤„ç†å•è¯: booster\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[175/414] å¤„ç†å•è¯: sarcastic\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[176/414] å¤„ç†å•è¯: airlock\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[177/414] å¤„ç†å•è¯: deactivate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[178/414] å¤„ç†å•è¯: rave\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[179/414] å¤„ç†å•è¯: condo\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[180/414] å¤„ç†å•è¯: gazelle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[181/414] å¤„ç†å•è¯: shred\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[182/414] å¤„ç†å•è¯: slingshot\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[183/414] å¤„ç†å•è¯: discretion\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[184/414] å¤„ç†å•è¯: slick\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[185/414] å¤„ç†å•è¯: pathology\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[186/414] å¤„ç†å•è¯: yachtsman\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[187/414] å¤„ç†å•è¯: overboard\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[188/414] å¤„ç†å•è¯: periscope\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[189/414] å¤„ç†å•è¯: navigationally\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[190/414] å¤„ç†å•è¯: spray\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[191/414] å¤„ç†å•è¯: distort\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[192/414] å¤„ç†å•è¯: neutron\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[193/414] å¤„ç†å•è¯: decelerate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[194/414] å¤„ç†å•è¯: pull something off\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[195/414] å¤„ç†å•è¯: debrief\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[196/414] å¤„ç†å•è¯: aerodynamics\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[197/414] å¤„ç†å•è¯: beacon\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[198/414] å¤„ç†å•è¯: spiral\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[199/414] å¤„ç†å•è¯: wreckage\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[200/414] å¤„ç†å•è¯: swell\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[201/414] å¤„ç†å•è¯: override\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[202/414] å¤„ç†å•è¯: slippage\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[203/414] å¤„ç†å•è¯: depressurize\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[204/414] å¤„ç†å•è¯: forty\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[205/414] å¤„ç†å•è¯: intrude\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[206/414] å¤„ç†å•è¯: rivet\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[207/414] å¤„ç†å•è¯: crack\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[208/414] å¤„ç†å•è¯: morbid\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[209/414] å¤„ç†å•è¯: recursive\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[210/414] å¤„ç†å•è¯: nonsensical\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[211/414] å¤„ç†å•è¯: lifespan\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[212/414] å¤„ç†å•è¯: stark\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[213/414] å¤„ç†å•è¯: undeniably\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[214/414] å¤„ç†å•è¯: alkali\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[215/414] å¤„ç†å•è¯: ammonia\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[216/414] å¤„ç†å•è¯: dissipate\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[217/414] å¤„ç†å•è¯: legwork\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[218/414] å¤„ç†å•è¯: degeneration\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[219/414] å¤„ç†å•è¯: decommission\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[220/414] å¤„ç†å•è¯: comm\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[221/414] å¤„ç†å•è¯: reconcile\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[222/414] å¤„ç†å•è¯: naked\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[223/414] å¤„ç†å•è¯: oyster\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[224/414] å¤„ç†å•è¯: monstrous\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[225/414] å¤„ç†å•è¯: arrogance\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[226/414] å¤„ç†å•è¯: auxiliary\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[227/414] å¤„ç†å•è¯: scrubber\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[228/414] å¤„ç†å•è¯: teary\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[229/414] å¤„ç†å•è¯: squall\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[230/414] å¤„ç†å•è¯: remiss\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[231/414] å¤„ç†å•è¯: improvise\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[232/414] å¤„ç†å•è¯: inspiration\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[233/414] å¤„ç†å•è¯: boot\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[234/414] å¤„ç†å•è¯: buddy\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[235/414] å¤„ç†å•è¯: abundantly\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[236/414] å¤„ç†å•è¯: temptation\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[237/414] å¤„ç†å•è¯: lockout\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[238/414] å¤„ç†å•è¯: maroon\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[239/414] å¤„ç†å•è¯: autopilot\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[240/414] å¤„ç†å•è¯: withhold\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[241/414] å¤„ç†å•è¯: disengaged\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[242/414] å¤„ç†å•è¯: retro\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[243/414] å¤„ç†å•è¯: black something out\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[244/414] å¤„ç†å•è¯: starboard\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[245/414] å¤„ç†å•è¯: scratch\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[246/414] å¤„ç†å•è¯: linkage\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[247/414] å¤„ç†å•è¯: nose\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[248/414] å¤„ç†å•è¯: turbulence\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[249/414] å¤„ç†å•è¯: exert\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[250/414] å¤„ç†å•è¯: affirmative\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[251/414] å¤„ç†å•è¯: bulk\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[252/414] å¤„ç†å•è¯: errand\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[253/414] å¤„ç†å•è¯: grill\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[254/414] å¤„ç†å•è¯: bureau\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[255/414] å¤„ç†å•è¯: criminology\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[256/414] å¤„ç†å•è¯: Magna Carta\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[257/414] å¤„ç†å•è¯: internship\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[258/414] å¤„ç†å•è¯: clinic\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[259/414] å¤„ç†å•è¯: interview\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[260/414] å¤„ç†å•è¯: psycho\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[261/414] å¤„ç†å•è¯: spook\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[262/414] å¤„ç†å•è¯: psychiatrist\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[263/414] å¤„ç†å•è¯: sketch\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[264/414] å¤„ç†å•è¯: dossier\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[265/414] å¤„ç†å•è¯: buffalo\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[266/414] å¤„ç†å•è¯: deviate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[267/414] å¤„ç†å•è¯: psychopath\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[268/414] å¤„ç†å•è¯: detective\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[269/414] å¤„ç†å•è¯: nemesis\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[270/414] å¤„ç†å•è¯: so to speak\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[271/414] å¤„ç†å•è¯: charm\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[272/414] å¤„ç†å•è¯: dispensary\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[273/414] å¤„ç†å•è¯: mouthpiece\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[274/414] å¤„ç†å•è¯: EKG\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[275/414] å¤„ç†å•è¯: trainee\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[276/414] å¤„ç†å•è¯: slippery\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[277/414] å¤„ç†å•è¯: hiss\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[278/414] å¤„ç†å•è¯: cream\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[279/414] å¤„ç†å•è¯: belvedere\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[280/414] å¤„ç†å•è¯: courteous\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[281/414] å¤„ç†å•è¯: receptive\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[282/414] å¤„ç†å•è¯: courtesy\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[283/414] å¤„ç†å•è¯: ham-handed\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[284/414] å¤„ç†å•è¯: segue\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[285/414] å¤„ç†å•è¯: homicide\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[286/414] å¤„ç†å•è¯: thrill\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[287/414] å¤„ç†å•è¯: acumen\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[288/414] å¤„ç†å•è¯: trophy\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[289/414] å¤„ç†å•è¯: dissect\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[290/414] å¤„ç†å•è¯: blunt\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[291/414] å¤„ç†å•è¯: hustle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[292/414] å¤„ç†å•è¯: rube\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[293/414] å¤„ç†å•è¯: desperately\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[294/414] å¤„ç†å•è¯: shed\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[295/414] å¤„ç†å•è¯: stink\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[296/414] å¤„ç†å•è¯: lamp\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[297/414] å¤„ç†å•è¯: tedious\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[298/414] å¤„ç†å•è¯: sticky\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[299/414] å¤„ç†å•è¯: census\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[300/414] å¤„ç†å•è¯: fava bean\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[301/414] å¤„ç†å•è¯: guru\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[302/414] å¤„ç†å•è¯: hokey\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[303/414] å¤„ç†å•è¯: detest\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[304/414] å¤„ç†å•è¯: anagram\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[305/414] å¤„ç†å•è¯: exotic\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[306/414] å¤„ç†å•è¯: tuck\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[307/414] å¤„ç†å•è¯: transvestite\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[308/414] å¤„ç†å•è¯: garden-variety\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[309/414] å¤„ç†å•è¯: manic depressive\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[310/414] å¤„ç†å•è¯: fledgling\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[311/414] å¤„ç†å•è¯: exhilarate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[312/414] å¤„ç†å•è¯: sexually\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[313/414] å¤„ç†å•è¯: torment\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[314/414] å¤„ç†å•è¯: decapitate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[315/414] å¤„ç†å•è¯: handicap\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[316/414] å¤„ç†å•è¯: mutilation\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[317/414] å¤„ç†å•è¯: post mortem\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[318/414] å¤„ç†å•è¯: abduct\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[319/414] å¤„ç†å•è¯: drifter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[320/414] å¤„ç†å•è¯: attorney\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[321/414] å¤„ç†å•è¯: sensitivity\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[322/414] å¤„ç†å•è¯: sternum\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[323/414] å¤„ç†å•è¯: muzzle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[324/414] å¤„ç†å•è¯: pathologist\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[325/414] å¤„ç†å•è¯: almighty\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[326/414] å¤„ç†å•è¯: pierce\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[327/414] å¤„ç†å•è¯: glitter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[328/414] å¤„ç†å•è¯: fingernail\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[329/414] å¤„ç†å•è¯: grit\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[330/414] å¤„ç†å•è¯: claw\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[331/414] å¤„ç†å•è¯: fax\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[332/414] å¤„ç†å•è¯: seed pod\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[333/414] å¤„ç†å•è¯: cocoon\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[334/414] å¤„ç†å•è¯: shove\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[335/414] å¤„ç†å•è¯: buttock\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[336/414] å¤„ç†å•è¯: thoracic\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[337/414] å¤„ç†å•è¯: vertebra\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[338/414] å¤„ç†å•è¯: blade\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[339/414] å¤„ç†å•è¯: sheriff\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[340/414] å¤„ç†å•è¯: ligature\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[341/414] å¤„ç†å•è¯: wrist\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[342/414] å¤„ç†å•è¯: mush\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[343/414] å¤„ç†å•è¯: morphology\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[344/414] å¤„ç†å•è¯: deadly nightshade\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[345/414] å¤„ç†å•è¯: turnkey\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[346/414] å¤„ç†å•è¯: tern\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[347/414] å¤„ç†å•è¯: burglar\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[348/414] å¤„ç†å•è¯: hip\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[349/414] å¤„ç†å•è¯: roomy\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[350/414] å¤„ç†å•è¯: moth\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[351/414] å¤„ç†å•è¯: caterpillar\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[352/414] å¤„ç†å•è¯: chrysalis\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[353/414] å¤„ç†å•è¯: pupa\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[354/414] å¤„ç†å•è¯: thence\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[355/414] å¤„ç†å•è¯: orphan\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[356/414] å¤„ç†å•è¯: ranch\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[357/414] å¤„ç†å•è¯: fellatio\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[358/414] å¤„ç†å•è¯: sodomize\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[359/414] å¤„ç†å•è¯: disturbance\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[360/414] å¤„ç†å•è¯: rub\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[361/414] å¤„ç†å•è¯: lotion\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[362/414] å¤„ç†å•è¯: hose\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[363/414] å¤„ç†å•è¯: birdie\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[364/414] å¤„ç†å•è¯: phoney\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[365/414] å¤„ç†å•è¯: sergeant\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[366/414] å¤„ç†å•è¯: cot\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[367/414] å¤„ç†å•è¯: affidavit\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[368/414] å¤„ç†å•è¯: transient\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[369/414] å¤„ç†å•è¯: toughen\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[370/414] å¤„ç†å•è¯: nipple\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[371/414] å¤„ç†å•è¯: amputate\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[372/414] å¤„ç†å•è¯: tickle\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[373/414] å¤„ç†å•è¯: slab\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[374/414] å¤„ç†å•è¯: pale\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[375/414] å¤„ç†å•è¯: apprehend\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[376/414] å¤„ç†å•è¯: vampire\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[377/414] å¤„ç†å•è¯: thoughtful\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[378/414] å¤„ç†å•è¯: wheedle\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[379/414] å¤„ç†å•è¯: sulfide\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[380/414] å¤„ç†å•è¯: incidental\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[381/414] å¤„ç†å•è¯: covet\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[382/414] å¤„ç†å•è¯: slaughter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[383/414] å¤„ç†å•è¯: pen\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[384/414] å¤„ç†å•è¯: chops\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[385/414] å¤„ç†å•è¯: cuff\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[386/414] å¤„ç†å•è¯: strip\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[387/414] å¤„ç†å•è¯: strap\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[388/414] å¤„ç†å•è¯: stairwell\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[389/414] å¤„ç†å•è¯: affirm\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[390/414] å¤„ç†å•è¯: laceration\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[391/414] å¤„ç†å•è¯: mal-\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[392/414] å¤„ç†å•è¯: seizure\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[393/414] å¤„ç†å•è¯: vital\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[394/414] å¤„ç†å•è¯: lactate\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[395/414] å¤„ç†å•è¯: liter\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[396/414] å¤„ç†å•è¯: cannibal\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[397/414] å¤„ç†å•è¯: scraps\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[398/414] å¤„ç†å•è¯: snack\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[399/414] å¤„ç†å•è¯: mister\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[400/414] å¤„ç†å•è¯: grenadier\n",
      "  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\n",
      "\n",
      "[401/414] å¤„ç†å•è¯: mole\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[402/414] å¤„ç†å•è¯: requisition\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[403/414] å¤„ç†å•è¯: life jacket\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[404/414] å¤„ç†å•è¯: gauge\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[405/414] å¤„ç†å•è¯: stretcher\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[406/414] å¤„ç†å•è¯: bowline\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[407/414] å¤„ç†å•è¯: gangplank\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[408/414] å¤„ç†å•è¯: rudder\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[409/414] å¤„ç†å•è¯: rear\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[410/414] å¤„ç†å•è¯: admiral\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[411/414] å¤„ç†å•è¯: destroyer\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[412/414] å¤„ç†å•è¯: Highlander\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[413/414] å¤„ç†å•è¯: bandit\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "[414/414] å¤„ç†å•è¯: barrage\n",
      "  âœ… Blanked_Examples å·²æ›´æ–°\n",
      "\n",
      "============================================================\n",
      "å¤„ç†å®Œæˆï¼\n",
      "æ›´æ–°: 315 ä¸ª\n",
      "è·³è¿‡: 0 ä¸ª\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "æ›´æ–° Media ç‰Œç»„ä¸­çš„ Blanked_Examples å­—æ®µ\n",
    "å¦‚æœ Blanked_Examples ä¸­æ²¡æœ‰ example-metaï¼Œå°±ä» Examples ä¸­å¤åˆ¶å¯¹åº”çš„ meta ä¿¡æ¯\n",
    "\"\"\"\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "code_dir = Path.cwd().parent if Path.cwd().name == 'utils' else Path.cwd()\n",
    "sys.path.insert(0, str(code_dir))\n",
    "\n",
    "from anki.anki import invoke as anki_invoke\n",
    "\n",
    "DECK_NAME = \"Media\"\n",
    "SKIP_FIRST_N = 0  # è·³è¿‡å‰ n ä¸ªç¬”è®°\n",
    "\n",
    "def update_blanked_examples_with_meta(blanked_examples_html: str, examples_html: str) -> str:\n",
    "    \"\"\"å¦‚æœ Blanked_Examples ä¸­æ²¡æœ‰ example-metaï¼Œå°±ä» Examples ä¸­å¤åˆ¶\"\"\"\n",
    "    if not blanked_examples_html or not examples_html:\n",
    "        return blanked_examples_html\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å·²ç»æœ‰ metaï¼ˆæ”¯æŒå•å¼•å·å’ŒåŒå¼•å·ï¼‰\n",
    "    if '<div class=\"example-meta\">' in blanked_examples_html or '<div class=\\'example-meta\\'>' in blanked_examples_html:\n",
    "        return blanked_examples_html\n",
    "    \n",
    "    # ä» Examples ä¸­æå–æ‰€æœ‰ meta ä¿¡æ¯ï¼ˆæ”¯æŒå•å¼•å·å’ŒåŒå¼•å·ï¼‰\n",
    "    meta_pattern = r'<div class=[\"\\']example-meta[\"\\']>([^<]+)</div>'\n",
    "    meta_list = re.findall(meta_pattern, examples_html)\n",
    "    \n",
    "    if not meta_list:\n",
    "        return blanked_examples_html\n",
    "    \n",
    "    # æ‰¾åˆ° Blanked_Examples ä¸­æ‰€æœ‰çš„ example div\n",
    "    # åŒ¹é…æ ¼å¼ï¼š<div class=\"example\"><div class=\"example-text\">...</div></div>\n",
    "    example_pattern = r'(<div class=[\"\\']example[\"\\']>.*?</div>\\s*</div>)'\n",
    "    parts = re.split(example_pattern, blanked_examples_html, flags=re.DOTALL)\n",
    "    \n",
    "    updated_parts = []\n",
    "    meta_index = 0\n",
    "    \n",
    "    for part in parts:\n",
    "        if '<div class=' in part and 'example' in part and '</div></div>' in part:\n",
    "            # è¿™æ˜¯ä¸€ä¸ª example divï¼Œåœ¨ </div></div> ä¹‹å‰æ’å…¥ meta\n",
    "            if meta_index < len(meta_list):\n",
    "                meta_text = meta_list[meta_index]\n",
    "                # åœ¨æœ€åä¸€ä¸ª </div> ä¹‹å‰æ’å…¥ meta\n",
    "                updated_part = part.replace(\n",
    "                    '</div></div>',\n",
    "                    f'<div class=\"example-meta\">{meta_text}</div></div>'\n",
    "                )\n",
    "                updated_parts.append(updated_part)\n",
    "                meta_index += 1\n",
    "            else:\n",
    "                updated_parts.append(part)\n",
    "        else:\n",
    "            updated_parts.append(part)\n",
    "    \n",
    "    return ''.join(updated_parts)\n",
    "\n",
    "# 1. è·å–æ‰€æœ‰ç¬”è®°\n",
    "query = f'deck:\"{DECK_NAME}\"'\n",
    "note_ids = anki_invoke(\"findNotes\", query=query).get(\"result\", [])\n",
    "\n",
    "print(f\"æ‰¾åˆ° {len(note_ids)} ä¸ªç¬”è®°\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 2. è·å–ç¬”è®°è¯¦æƒ…\n",
    "notes_info = anki_invoke(\"notesInfo\", notes=note_ids).get(\"result\", [])\n",
    "\n",
    "updated_count = 0\n",
    "skip_count = 0\n",
    "\n",
    "# 3. éå†å¹¶æ›´æ–°\n",
    "for i, note in enumerate(notes_info, 1):\n",
    "    if i <= SKIP_FIRST_N:\n",
    "        continue\n",
    "    \n",
    "    note_id = note.get(\"noteId\")\n",
    "    fields = note.get(\"fields\", {})\n",
    "    word = fields.get(\"Word\", {}).get(\"value\", \"\").strip()\n",
    "    \n",
    "    if not word:\n",
    "        print(f\"[{i}/{len(notes_info)}] âš ï¸  è·³è¿‡ï¼šæ²¡æœ‰ Word å­—æ®µ\")\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n[{i}/{len(notes_info)}] å¤„ç†å•è¯: {word}\")\n",
    "    \n",
    "    # è·å– Examples å’Œ Blanked_Examples\n",
    "    examples = fields.get(\"Examples\", {}).get(\"value\", \"\")\n",
    "    blanked_examples = fields.get(\"Blanked_Examples\", {}).get(\"value\", \"\")\n",
    "    \n",
    "    if not blanked_examples:\n",
    "        print(f\"  â­ï¸  Blanked_Examples ä¸ºç©ºï¼Œè·³è¿‡\")\n",
    "        skip_count += 1\n",
    "        continue\n",
    "    \n",
    "    # æ›´æ–° Blanked_Examples\n",
    "    updated_blanked_html = update_blanked_examples_with_meta(blanked_examples, examples)\n",
    "    \n",
    "    if updated_blanked_html != blanked_examples:\n",
    "        try:\n",
    "            result = anki_invoke(\"updateNoteFields\", \n",
    "                               note={\"id\": note_id, \n",
    "                                    \"fields\": {\"Blanked_Examples\": updated_blanked_html}})\n",
    "            if result and not result.get(\"error\"):\n",
    "                print(f\"  âœ… Blanked_Examples å·²æ›´æ–°\")\n",
    "                updated_count += 1\n",
    "            else:\n",
    "                error_msg = result.get(\"error\", \"æœªçŸ¥é”™è¯¯\") if result else \"æ— å“åº”\"\n",
    "                print(f\"  âŒ æ›´æ–°å¤±è´¥: {error_msg}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  âŒ æ›´æ–°å¼‚å¸¸: {e}\")\n",
    "    else:\n",
    "        print(f\"  â­ï¸  å·²æœ‰ meta æˆ–æ— éœ€æ›´æ–°\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"å¤„ç†å®Œæˆï¼\")\n",
    "print(f\"æ›´æ–°: {updated_count} ä¸ª\")\n",
    "print(f\"è·³è¿‡: {skip_count} ä¸ª\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94dc450",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
